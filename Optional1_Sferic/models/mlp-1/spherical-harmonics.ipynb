{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch-summary in /usr/local/lib/python3.10/dist-packages (1.4.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.62.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.24.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (5.26.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install torch-summary\n",
    "!pip install -U scikit-learn\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOULD_PRINT = False\n",
    "SEED = 32\n",
    "CONTINUE_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7feadcb7e070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, large_file_path, chunk_size, subset_size=50000):\n",
    "        self.large_file_path = large_file_path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.subset_size = subset_size\n",
    "        self.line_offsets = self.get_line_offsets(large_file_path, chunk_size)\n",
    "        self.scaler = StandardScaler()\n",
    "        print(\"Calculating mean and std...\")\n",
    "        self.mean, self.std = self.calculate_mean_std()\n",
    "        print(f\"Mean: {self.mean}, Std: {self.std}\")\n",
    "\n",
    "    def get_line_offsets(self, path: str, chunk_size: int) -> List[int]:\n",
    "        offsets = [0]\n",
    "        with open(path, \"rb\") as file:\n",
    "            chunk = file.readlines(chunk_size)\n",
    "            while chunk:\n",
    "                for line in chunk:\n",
    "                    offsets.append(offsets[-1] + len(line))\n",
    "                chunk = file.readlines(chunk_size)\n",
    "                print(f\"Lines found: {len(offsets)}\", end='\\r')\n",
    "        offsets = offsets[:-1]\n",
    "        print(f\"Lines found: {len(offsets)}\", end='\\n')\n",
    "        return offsets\n",
    "\n",
    "    def calculate_mean_std(self):\n",
    "        selected_offsets = random.sample(self.line_offsets, min(self.subset_size, len(self.line_offsets)))\n",
    "        features = []\n",
    "        for offset in selected_offsets:\n",
    "            with open(self.large_file_path, 'r', encoding='utf-8') as f:\n",
    "                f.seek(offset)\n",
    "                line = f.readline()\n",
    "                numbers = [float(num) for num in line.strip().split()]\n",
    "                features.append(numbers[:4])\n",
    "        features = np.array(features)\n",
    "        mean = np.mean(features, axis=0, dtype=np.float32)\n",
    "        std = np.std(features, axis=0, dtype=np.float32)\n",
    "        return mean, std\n",
    "\n",
    "    def standardize_features(self, features):\n",
    "        standardized_features = (features - self.mean) / self.std\n",
    "        return standardized_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offsets)\n",
    "\n",
    "    def __getitem__(self, line):\n",
    "        offset = self.line_offsets[line]\n",
    "        with open(self.large_file_path, 'r', encoding='utf-8') as f:\n",
    "            f.seek(offset)\n",
    "            line = f.readline()\n",
    "            numbers = [float(num) for num in line.strip().split()]\n",
    "            features, targets = numbers[:4], numbers[4:]\n",
    "            standardized_features = self.standardize_features(np.array(features))\n",
    "            return torch.tensor(standardized_features, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines found: 7154565\n",
      "Calculating mean and std...\n",
      "Mean: [24.44138   -0.08456    1.5601013  3.1256266], Std: [ 8.828163  14.960381   0.9234254  1.8104719]\n"
     ]
    }
   ],
   "source": [
    "filename = \"full_dataset_2.txt\"\n",
    "full_dataset = CustomDataset(filename, 2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(full_dataset))\n",
    "rest_size = len(full_dataset) - train_size\n",
    "val_size = rest_size // 10\n",
    "test_size = rest_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5008195"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 2 ** 19\n",
    "train_shuffle = True\n",
    "val_shuffle = False\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=train_shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=val_shuffle)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_layers, out_layers):\n",
    "        super(Block, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_layers, out_layers),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(4, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "        ])\n",
    "        self.out = nn.Linear(256, 2)\n",
    "        \n",
    "        self.__init_weights()\n",
    "\n",
    "    def __init_weights(self):\n",
    "        layers = [self.blocks]\n",
    "        # Initialize linear layers using Kaiming (He) uniform initialization\n",
    "        for m in layers:\n",
    "            for layer in m:\n",
    "                self.__init_layer(layer)\n",
    "        self.__init_layer(self.out)\n",
    "                        \n",
    "    def __init_layer(self, layer):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            init.kaiming_uniform_(layer.weight, mode='fan_in', nonlinearity='tanh')\n",
    "            if layer.bias is not None:\n",
    "                init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks[0](x)\n",
    "        for block in self.blocks[1:]:\n",
    "            y = block(x)\n",
    "            x = x + y\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 5e-3\n",
    "NUM_EPOCHS = 50\n",
    "WEIGHT_DECAY = 0.99\n",
    "WEIGHT_DECAY_L1 = 1e-4\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "last_epoch = 0\n",
    "model = MLP()\n",
    "loss_mse = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY, nesterov=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=1.0,\n",
    "    end_factor=0.2,\n",
    "    total_iters=int(NUM_EPOCHS * 0.75))\n",
    "# scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, verbose=True) # set it to 10 next time because 1 epoch = 1 batch!\n",
    "if CONTINUE_MODEL:\n",
    "    checkpoint = torch.load(\"checkpoint.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_mse = checkpoint['loss_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(model, (BATCH_SIZE, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train(model, dataloader, optimizer, scheduler, loss_fn, epoch, writer, log_perc = 0.1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_diff = 0\n",
    "\n",
    "    logs_steps = max(int(log_perc * len(dataloader)), 1)\n",
    "    start_step = epoch * len(dataloader)\n",
    "\n",
    "    before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    writer.add_scalar('Lr/Train', before_lr, epoch)\n",
    "    for idx, (inputs, targets) in enumerate(tqdm(dataloader)):\n",
    "        inputs, targets = inputs.to(device).to(torch.float32), targets.to(device).to(torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        diff = torch.abs(outputs - targets).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_diff += diff.item()\n",
    "        \n",
    "        if idx % logs_steps == 0:\n",
    "            writer.add_scalar('Loss/Train', loss.item(), start_step + idx)\n",
    "            writer.add_scalar('Absolute Difference/Train', diff.item(), start_step + idx)\n",
    "            \n",
    "            if SHOULD_PRINT:\n",
    "                print(f\"Loss/Train: {loss.item()}\")\n",
    "                print(f\"Absolute Difference/Train: {diff.item()}\")\n",
    "        \n",
    "    after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    average_diff = total_diff / len(dataloader)\n",
    "    \n",
    "    writer.add_scalar('Avg Loss/Train', average_loss, epoch)\n",
    "    writer.add_scalar('Avg Absolute Difference/Train', average_diff, epoch)\n",
    "    writer.add_scalar('Lr/Train', after_lr, epoch)\n",
    "    \n",
    "    # if SHOULD_PRINT:\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Avg Loss/Train: {average_loss}\")\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Avg Absolute Difference/Train: {average_diff}\")\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Lr/Train: {after_lr}\")\n",
    "\n",
    "    # print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Train Loss: {average_loss:.4f}, Train Diff: {average_diff:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, loss_fn, epoch, writer):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_diff = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device).to(torch.float32), targets.to(device).to(torch.float32)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            diff = torch.abs(outputs - targets).mean()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_diff += diff.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    average_diff = total_diff / len(dataloader)\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('Avg Loss/Val', average_loss, epoch)\n",
    "        writer.add_scalar('Avg Absolute Difference/Val', average_diff, epoch)\n",
    "    \n",
    "    if SHOULD_PRINT:\n",
    "        print(f\"Avg Loss/Val: {average_loss}\")\n",
    "        print(f\"Avg Absolute Difference/Val: {average_diff}\")\n",
    "\n",
    "    if epoch is not None:\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Val Loss: {average_loss:.4f}, Val Diff: {average_diff:.15f}\")\n",
    "    else:\n",
    "        print(f\"Test Loss: {average_loss:.4f}, Test Diff: {average_diff:.15f}\")\n",
    "        \n",
    "    return average_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(outputs, targets):\n",
    "    loss = loss_mse(outputs, targets)\n",
    "#     loss_rmse = torch.sqrt(loss)\n",
    "#     l1_reg = torch.tensor(0., requires_grad=True)\n",
    "\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if 'weight' in name:\n",
    "#             l1_reg = l1_reg + torch.linalg.norm(param, 1)\n",
    "\n",
    "#     total_loss = (loss * 0.8 + loss_rmse * 0.2) + WEIGHT_DECAY_L1 * l1_reg\n",
    "#     total_loss = (loss * 0.8 + loss_rmse * 0.2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:29<00:00, 32.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Avg Loss/Train: 1.151175606250763\n",
      "Epoch [1/50] Avg Absolute Difference/Train: 0.8387817859649658\n",
      "Epoch [1/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [1/50] Val Loss: 0.5100, Val Diff: 0.651699721813202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:25<00:00, 32.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Avg Loss/Train: 0.900682270526886\n",
      "Epoch [2/50] Avg Absolute Difference/Train: 0.7172548770904541\n",
      "Epoch [2/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:26<00:00, 32.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Avg Loss/Train: 0.7404113113880157\n",
      "Epoch [3/50] Avg Absolute Difference/Train: 0.6290013253688812\n",
      "Epoch [3/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:29<00:00, 32.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Avg Loss/Train: 0.6341127693653107\n",
      "Epoch [4/50] Avg Absolute Difference/Train: 0.5674039840698242\n",
      "Epoch [4/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:26<00:00, 32.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Avg Loss/Train: 0.5620494306087493\n",
      "Epoch [5/50] Avg Absolute Difference/Train: 0.5263272941112518\n",
      "Epoch [5/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:28<00:00, 32.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Avg Loss/Train: 0.5085949510335922\n",
      "Epoch [6/50] Avg Absolute Difference/Train: 0.4972809165716171\n",
      "Epoch [6/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:27<00:00, 32.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Avg Loss/Train: 0.46763978600502015\n",
      "Epoch [7/50] Avg Absolute Difference/Train: 0.4757583498954773\n",
      "Epoch [7/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [7/50] Val Loss: 0.1101, Val Diff: 0.274005800485611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:26<00:00, 32.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Avg Loss/Train: 0.4334012746810913\n",
      "Epoch [8/50] Avg Absolute Difference/Train: 0.45819670259952544\n",
      "Epoch [8/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:23<00:00, 32.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Avg Loss/Train: 0.4026907473802567\n",
      "Epoch [9/50] Avg Absolute Difference/Train: 0.44222576916217804\n",
      "Epoch [9/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:23<00:00, 32.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Avg Loss/Train: 0.37700113356113435\n",
      "Epoch [10/50] Avg Absolute Difference/Train: 0.4287463128566742\n",
      "Epoch [10/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:23<00:00, 32.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Avg Loss/Train: 0.35358095467090606\n",
      "Epoch [11/50] Avg Absolute Difference/Train: 0.41605142652988436\n",
      "Epoch [11/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:26<00:00, 32.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Avg Loss/Train: 0.33181234300136564\n",
      "Epoch [12/50] Avg Absolute Difference/Train: 0.4039364218711853\n",
      "Epoch [12/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:30<00:00, 33.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Avg Loss/Train: 0.3131508529186249\n",
      "Epoch [13/50] Avg Absolute Difference/Train: 0.3930457979440689\n",
      "Epoch [13/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [13/50] Val Loss: 0.0758, Val Diff: 0.221599087119102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:27<00:00, 32.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Avg Loss/Train: 0.29553642570972444\n",
      "Epoch [14/50] Avg Absolute Difference/Train: 0.3825806736946106\n",
      "Epoch [14/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:25<00:00, 32.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Avg Loss/Train: 0.27930082082748414\n",
      "Epoch [15/50] Avg Absolute Difference/Train: 0.37263399362564087\n",
      "Epoch [15/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:27<00:00, 32.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Avg Loss/Train: 0.26437766551971437\n",
      "Epoch [16/50] Avg Absolute Difference/Train: 0.3631796151399612\n",
      "Epoch [16/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:28<00:00, 32.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Avg Loss/Train: 0.25087847262620927\n",
      "Epoch [17/50] Avg Absolute Difference/Train: 0.3543669909238815\n",
      "Epoch [17/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:27<00:00, 32.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Avg Loss/Train: 0.23840224891901016\n",
      "Epoch [18/50] Avg Absolute Difference/Train: 0.3460749387741089\n",
      "Epoch [18/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Avg Loss/Train: 0.22650967240333558\n",
      "Epoch [19/50] Avg Absolute Difference/Train: 0.3379148572683334\n",
      "Epoch [19/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [19/50] Val Loss: 0.0644, Val Diff: 0.201059669256210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:27<00:00, 32.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Avg Loss/Train: 0.21529565006494522\n",
      "Epoch [20/50] Avg Absolute Difference/Train: 0.33001886010169984\n",
      "Epoch [20/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:28<00:00, 32.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Avg Loss/Train: 0.20492856055498124\n",
      "Epoch [21/50] Avg Absolute Difference/Train: 0.32244742214679717\n",
      "Epoch [21/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:31<00:00, 33.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Avg Loss/Train: 0.1957403004169464\n",
      "Epoch [22/50] Avg Absolute Difference/Train: 0.31563332974910735\n",
      "Epoch [22/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Avg Loss/Train: 0.18656120002269744\n",
      "Epoch [23/50] Avg Absolute Difference/Train: 0.3087324291467667\n",
      "Epoch [23/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:25<00:00, 32.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Avg Loss/Train: 0.17820748388767244\n",
      "Epoch [24/50] Avg Absolute Difference/Train: 0.3021861702203751\n",
      "Epoch [24/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Avg Loss/Train: 0.1704728499054909\n",
      "Epoch [25/50] Avg Absolute Difference/Train: 0.2958842068910599\n",
      "Epoch [25/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [25/50] Val Loss: 0.0577, Val Diff: 0.187721759080887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:22<00:00, 32.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Avg Loss/Train: 0.16312939077615737\n",
      "Epoch [26/50] Avg Absolute Difference/Train: 0.28989691436290743\n",
      "Epoch [26/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:22<00:00, 32.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Avg Loss/Train: 0.1563908040523529\n",
      "Epoch [27/50] Avg Absolute Difference/Train: 0.2842616528272629\n",
      "Epoch [27/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:23<00:00, 32.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Avg Loss/Train: 0.150210964679718\n",
      "Epoch [28/50] Avg Absolute Difference/Train: 0.27898287773132324\n",
      "Epoch [28/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:22<00:00, 32.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Avg Loss/Train: 0.14422188997268676\n",
      "Epoch [29/50] Avg Absolute Difference/Train: 0.27372013628482816\n",
      "Epoch [29/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:25<00:00, 32.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Avg Loss/Train: 0.13860013633966445\n",
      "Epoch [30/50] Avg Absolute Difference/Train: 0.26869012117385865\n",
      "Epoch [30/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Avg Loss/Train: 0.13319262117147446\n",
      "Epoch [31/50] Avg Absolute Difference/Train: 0.2637252241373062\n",
      "Epoch [31/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [31/50] Val Loss: 0.0533, Val Diff: 0.177985802292824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:23<00:00, 32.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Avg Loss/Train: 0.1282310038805008\n",
      "Epoch [32/50] Avg Absolute Difference/Train: 0.25910704731941225\n",
      "Epoch [32/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:26<00:00, 32.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Avg Loss/Train: 0.12342175245285034\n",
      "Epoch [33/50] Avg Absolute Difference/Train: 0.2545392125844955\n",
      "Epoch [33/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Avg Loss/Train: 0.11916653141379356\n",
      "Epoch [34/50] Avg Absolute Difference/Train: 0.25032072365283964\n",
      "Epoch [34/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:27<00:00, 32.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Avg Loss/Train: 0.11483245715498924\n",
      "Epoch [35/50] Avg Absolute Difference/Train: 0.24605446308851242\n",
      "Epoch [35/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:25<00:00, 32.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Avg Loss/Train: 0.11091845259070396\n",
      "Epoch [36/50] Avg Absolute Difference/Train: 0.24201937168836593\n",
      "Epoch [36/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:22<00:00, 32.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Avg Loss/Train: 0.1073471486568451\n",
      "Epoch [37/50] Avg Absolute Difference/Train: 0.23835665732622147\n",
      "Epoch [37/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [37/50] Val Loss: 0.0503, Val Diff: 0.170563623309135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Avg Loss/Train: 0.10386322811245918\n",
      "Epoch [38/50] Avg Absolute Difference/Train: 0.23462091386318207\n",
      "Epoch [38/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:26<00:00, 32.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Avg Loss/Train: 0.10051489099860192\n",
      "Epoch [39/50] Avg Absolute Difference/Train: 0.23097633421421052\n",
      "Epoch [39/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Avg Loss/Train: 0.09747198149561882\n",
      "Epoch [40/50] Avg Absolute Difference/Train: 0.22758155912160874\n",
      "Epoch [40/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:26<00:00, 32.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Avg Loss/Train: 0.09455850347876549\n",
      "Epoch [41/50] Avg Absolute Difference/Train: 0.2243245080113411\n",
      "Epoch [41/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:27<00:00, 32.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Avg Loss/Train: 0.091900385171175\n",
      "Epoch [42/50] Avg Absolute Difference/Train: 0.2212494507431984\n",
      "Epoch [42/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:24<00:00, 32.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Avg Loss/Train: 0.089308762550354\n",
      "Epoch [43/50] Avg Absolute Difference/Train: 0.21822268813848494\n",
      "Epoch [43/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [43/50] Val Loss: 0.0481, Val Diff: 0.164729103446007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:22<00:00, 32.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Avg Loss/Train: 0.08674260452389718\n",
      "Epoch [44/50] Avg Absolute Difference/Train: 0.215212619304657\n",
      "Epoch [44/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:25<00:00, 32.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Avg Loss/Train: 0.08439482674002648\n",
      "Epoch [45/50] Avg Absolute Difference/Train: 0.21231389194726943\n",
      "Epoch [45/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:29<00:00, 32.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Avg Loss/Train: 0.08224377632141114\n",
      "Epoch [46/50] Avg Absolute Difference/Train: 0.20970220863819122\n",
      "Epoch [46/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:23<00:00, 32.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Avg Loss/Train: 0.08017288669943809\n",
      "Epoch [47/50] Avg Absolute Difference/Train: 0.2069874420762062\n",
      "Epoch [47/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:28<00:00, 32.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Avg Loss/Train: 0.07815141454339028\n",
      "Epoch [48/50] Avg Absolute Difference/Train: 0.20449622273445128\n",
      "Epoch [48/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:27<00:00, 32.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Avg Loss/Train: 0.07629864066839218\n",
      "Epoch [49/50] Avg Absolute Difference/Train: 0.20210305750370025\n",
      "Epoch [49/50] Lr/Train: 0.0009999999999999998\n",
      "Epoch [49/50] Val Loss: 0.0464, Val Diff: 0.160024866461754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:25<00:00, 32.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Avg Loss/Train: 0.07458398714661599\n",
      "Epoch [50/50] Avg Absolute Difference/Train: 0.19977545440196992\n",
      "Epoch [50/50] Lr/Train: 0.0009999999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(f\"tb_logs/{now}\")\n",
    "\n",
    "VALIDATION_STEPS = 6\n",
    "\n",
    "model = model.to(device)\n",
    "best_avg_diff = 1000\n",
    "\n",
    "for idx, epoch in enumerate(range(last_epoch, NUM_EPOCHS)):\n",
    "    train(model, train_dataloader, optimizer, scheduler, total_loss, epoch, writer, log_perc=0.2)\n",
    "\n",
    "    if idx % VALIDATION_STEPS == 0:\n",
    "        average_diff = validate(model, val_dataloader, total_loss, epoch, writer)\n",
    "        if average_diff < best_avg_diff:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss_mse': loss_mse,\n",
    "                }, \"checkpoint.pth\")\n",
    "\n",
    "# Launch TensorBoard: `tensorboard --logdir=tb_logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.044784296836171834\n",
      "Avg Absolute Difference/Val: 0.14934985978262766\n",
      "Epoch [48/48] Val Loss: 0.0448, Val Diff: 0.149349859782628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14934985978262766"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, test_dataloader, total_loss, epoch, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4578667,
     "sourceId": 7960124,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 18456,
     "sourceId": 22283,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
