{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7815780,"sourceType":"datasetVersion","datasetId":4578667}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:28:23.566496Z","iopub.execute_input":"2024-03-11T14:28:23.566849Z","iopub.status.idle":"2024-03-11T14:28:36.794097Z","shell.execute_reply.started":"2024-03-11T14:28:23.566819Z","shell.execute_reply":"2024-03-11T14:28:36.792989Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"SHOULD_PRINT = False","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:28:36.795998Z","iopub.execute_input":"2024-03-11T14:28:36.796301Z","iopub.status.idle":"2024-03-11T14:28:36.800797Z","shell.execute_reply.started":"2024-03-11T14:28:36.796276Z","shell.execute_reply":"2024-03-11T14:28:36.799866Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:28:36.802020Z","iopub.execute_input":"2024-03-11T14:28:36.802334Z","iopub.status.idle":"2024-03-11T14:28:39.934690Z","shell.execute_reply.started":"2024-03-11T14:28:36.802310Z","shell.execute_reply":"2024-03-11T14:28:39.933924Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n    def __init__(self, filename):\n        self.data = []\n        with open(filename, 'r') as f:\n            for line in f:\n                numbers = [float(num) for num in line.strip().split()]\n                self.data.append((numbers[:4], numbers[4:]))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        inputs, targets = self.data[idx]\n        return torch.tensor(inputs), torch.tensor(targets)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:28:39.936408Z","iopub.execute_input":"2024-03-11T14:28:39.936757Z","iopub.status.idle":"2024-03-11T14:28:39.943818Z","shell.execute_reply.started":"2024-03-11T14:28:39.936734Z","shell.execute_reply":"2024-03-11T14:28:39.942954Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"filename = \"/kaggle/input/harmonic/sph_100_10_20.txt\"\nfull_dataset = CustomDataset(filename)\n\ntrain_size = int(0.8 * len(full_dataset))\nrest_size = len(full_dataset) - train_size\nval_size = rest_size // 2\ntest_size = rest_size // 2\ntrain_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(32))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:28:39.944912Z","iopub.execute_input":"2024-03-11T14:28:39.945235Z","iopub.status.idle":"2024-03-11T14:28:40.166308Z","shell.execute_reply.started":"2024-03-11T14:28:39.945206Z","shell.execute_reply":"2024-03-11T14:28:40.165463Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nBATCH_SIZE = 1024\ntrain_shuffle = True\nval_shuffle = False\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=train_shuffle)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=val_shuffle)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:14.194339Z","iopub.execute_input":"2024-03-11T14:19:14.194620Z","iopub.status.idle":"2024-03-11T14:19:14.200629Z","shell.execute_reply.started":"2024-03-11T14:19:14.194595Z","shell.execute_reply":"2024-03-11T14:19:14.199618Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"for inputs, targets in train_dataloader:\n    assert inputs.shape[1] == 4 and targets.shape[1] == 2","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:14.202371Z","iopub.execute_input":"2024-03-11T14:19:14.202674Z","iopub.status.idle":"2024-03-11T14:19:14.949307Z","shell.execute_reply.started":"2024-03-11T14:19:14.202642Z","shell.execute_reply":"2024-03-11T14:19:14.948372Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.init as init\n\nclass MLP(nn.Module):\n    def __init__(self):\n        super(MLP, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(4, 128),\n            nn.Tanh(),\n            nn.Linear(128, 128),\n            nn.Tanh(),\n            nn.Linear(128, 2)\n        )\n        self.__init_weights()\n\n    def __init_weights(self):\n        # Initialize linear layers using Kaiming (He) uniform initialization\n        for m in self.layers.children():\n            if isinstance(m, nn.Linear):\n                init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='tanh')\n                if m.bias is not None:\n                    init.zeros_(m.bias)\n\n    def forward(self, x):\n        return self.layers(x)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:14.950745Z","iopub.execute_input":"2024-03-11T14:19:14.952513Z","iopub.status.idle":"2024-03-11T14:19:14.962544Z","shell.execute_reply.started":"2024-03-11T14:19:14.952483Z","shell.execute_reply":"2024-03-11T14:19:14.961660Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"LR = 3e-5\nNUM_EPOCHS = 50000\nMOMENTUM = 0.9\nWEIGHT_DECAY = 0.999\nMOMENTUM = 0.9","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:14.963507Z","iopub.execute_input":"2024-03-11T14:19:14.963795Z","iopub.status.idle":"2024-03-11T14:19:14.975279Z","shell.execute_reply.started":"2024-03-11T14:19:14.963762Z","shell.execute_reply":"2024-03-11T14:19:14.974477Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"device = \"cpu\"\nif torch.cuda.is_available():\n    device = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:14.976376Z","iopub.execute_input":"2024-03-11T14:19:14.976739Z","iopub.status.idle":"2024-03-11T14:19:14.983955Z","shell.execute_reply.started":"2024-03-11T14:19:14.976705Z","shell.execute_reply":"2024-03-11T14:19:14.983145Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\nmodel = MLP()\nloss_fn = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\nscheduler = lr_scheduler.LinearLR(\n    optimizer,\n    start_factor=1.0,\n    end_factor=0.3,\n    total_iters=NUM_EPOCHS / 0.20)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:14.985063Z","iopub.execute_input":"2024-03-11T14:19:14.985454Z","iopub.status.idle":"2024-03-11T14:19:14.995936Z","shell.execute_reply.started":"2024-03-11T14:19:14.985423Z","shell.execute_reply":"2024-03-11T14:19:14.995083Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\ndef train(model, dataloader, optimizer, scheduler, loss_fn, epoch, writer, log_perc = 0.1):\n    model.train()\n    total_loss = 0\n    total_diff = 0\n    best_diff = 100\n\n    logs_steps = int(log_perc * len(dataloader))\n    start_step = epoch * len(dataloader)\n\n    before_lr = optimizer.param_groups[0][\"lr\"]\n    writer.add_scalar('Lr/Train', before_lr, epoch)\n    for idx, (inputs, targets) in enumerate(dataloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n\n        loss = loss_fn(outputs, targets)\n        diff = torch.abs(outputs - targets).mean()\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        total_diff += diff.item()\n        \n        if idx % logs_steps == 0:\n            writer.add_scalar('Loss/Train', loss.item(), start_step + idx)\n            writer.add_scalar('Absolute Difference/Train', diff.item(), start_step + idx)\n            \n            if SHOULD_PRINT:\n                print(f\"Loss/Train: {loss.item()}\")\n                print(f\"Absolute Difference/Train: {diff.item()}\")\n\n    scheduler.step()\n    after_lr = optimizer.param_groups[0][\"lr\"]\n    average_loss = total_loss / len(dataloader)\n    average_diff = total_diff / len(dataloader)\n    \n    writer.add_scalar('Avg Loss/Train', average_loss, epoch)\n    writer.add_scalar('Avg Absolute Difference/Train', average_diff, epoch)\n    writer.add_scalar('Lr/Train', after_lr, epoch)\n    \n    if SHOULD_PRINT:\n        print(f\"Avg Loss/Train: {average_loss}\")\n        print(f\"Absolute Difference/Train: {average_diff}\")\n        print(f\"Lr/Train: {after_lr}\")\n\n    # print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Train Loss: {average_loss:.4f}, Train Diff: {average_diff:.15f}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:14.997213Z","iopub.execute_input":"2024-03-11T14:19:14.997815Z","iopub.status.idle":"2024-03-11T14:19:15.009155Z","shell.execute_reply.started":"2024-03-11T14:19:14.997764Z","shell.execute_reply":"2024-03-11T14:19:15.008285Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, loss_fn, epoch, writer):\n    model.eval()\n    total_loss = 0\n    total_diff = 0\n\n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n\n            loss = loss_fn(outputs, targets)\n            diff = torch.abs(outputs - targets).mean()\n            \n            total_loss += loss.item()\n            total_diff += diff.item()\n\n    average_loss = total_loss / len(dataloader)\n    average_diff = total_diff / len(dataloader)\n\n    if writer is not None:\n        writer.add_scalar('Avg Loss/Val', average_loss, epoch)\n        writer.add_scalar('Avg Absolute Difference/Val', average_diff, epoch)\n    \n    if SHOULD_PRINT:\n        print(f\"Avg Loss/Val: {average_loss}\")\n        print(f\"Avg Absolute Difference/Val: {average_diff}\")\n\n    if epoch is not None:\n        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Val Loss: {average_loss:.4f}, Val Diff: {average_diff:.15f}\")\n    else:\n        print(f\"Test Loss: {average_loss:.4f}, Test Diff: {average_diff:.15f}\")\n        \n    return average_diff","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:15.010476Z","iopub.execute_input":"2024-03-11T14:19:15.010843Z","iopub.status.idle":"2024-03-11T14:19:15.022112Z","shell.execute_reply.started":"2024-03-11T14:19:15.010813Z","shell.execute_reply":"2024-03-11T14:19:15.021404Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"import datetime\n\nnow = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nwriter = SummaryWriter(f\"tb_logs/{now}\")\n\nVALIDATION_STEPS = NUM_EPOCHS * 0.01\n\nmodel = model.to(device)\nbest_avg_diff = 1000\nfor idx, epoch in enumerate(tqdm(range(NUM_EPOCHS))):\n    train(model, train_dataloader, optimizer, scheduler, loss_fn, epoch, writer)\n\n    if idx % VALIDATION_STEPS == 0:\n        average_diff = validate(model, val_dataloader, loss_fn, epoch, writer)\n        if average_diff < best_avg_diff:\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'loss': loss_fn,\n                }, \"checkpoint.pth\")\n\n# Launch TensorBoard: `tensorboard --logdir=tb_logs`","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:23.786670Z","iopub.execute_input":"2024-03-11T14:19:23.787386Z","iopub.status.idle":"2024-03-11T14:19:27.194026Z","shell.execute_reply.started":"2024-03-11T14:19:23.787354Z","shell.execute_reply":"2024-03-11T14:19:27.192687Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stderr","text":"  0%|          | 1/50000 [00:00<5:30:47,  2.52it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/50000] Val Loss: 1.8047, Val Diff: 1.204378763834635\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 9/50000 [00:03<5:00:48,  2.77it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[105], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m best_avg_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(\u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS))):\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m VALIDATION_STEPS \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m         average_diff \u001b[38;5;241m=\u001b[39m validate(model, val_dataloader, loss_fn, epoch, writer)\n","Cell \u001b[0;32mIn[102], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, scheduler, loss_fn, epoch, writer, log_perc)\u001b[0m\n\u001b[1;32m     12\u001b[0m before_lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLr/Train\u001b[39m\u001b[38;5;124m'\u001b[39m, before_lr, epoch)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     15\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","Cell \u001b[0;32mIn[94], line 16\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     15\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(targets)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"validate(model, test_dataloader, loss_fn, epoch, None)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T14:19:15.471094Z","iopub.status.idle":"2024-03-11T14:19:15.471573Z","shell.execute_reply.started":"2024-03-11T14:19:15.471336Z","shell.execute_reply":"2024-03-11T14:19:15.471356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}