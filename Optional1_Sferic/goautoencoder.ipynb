{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7815780,"sourceType":"datasetVersion","datasetId":4578667}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"SHOULD_PRINT = False","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:35:08.390629Z","iopub.execute_input":"2024-03-16T21:35:08.390937Z","iopub.status.idle":"2024-03-16T21:35:08.395041Z","shell.execute_reply.started":"2024-03-16T21:35:08.390916Z","shell.execute_reply":"2024-03-16T21:35:08.394175Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:35:08.761888Z","iopub.execute_input":"2024-03-16T21:35:08.762188Z","iopub.status.idle":"2024-03-16T21:35:08.766358Z","shell.execute_reply.started":"2024-03-16T21:35:08.762167Z","shell.execute_reply":"2024-03-16T21:35:08.765470Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.manual_seed(32)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:35:10.687336Z","iopub.execute_input":"2024-03-16T21:35:10.687632Z","iopub.status.idle":"2024-03-16T21:35:10.692805Z","shell.execute_reply.started":"2024-03-16T21:35:10.687610Z","shell.execute_reply":"2024-03-16T21:35:10.692136Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7c4830b27270>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset \n\nclass CustomDataset(Dataset):\n    def __init__(self, filename):\n        self.data = []\n        with open(filename, 'r') as f:\n            for line in f:\n                numbers = [float(num) for num in line.strip().split()]\n                self.data.append((numbers[:4], numbers[4:]))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        inputs, targets = self.data[idx]\n        return torch.tensor(inputs), torch.tensor(targets)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:35:34.448124Z","iopub.execute_input":"2024-03-16T21:35:34.448707Z","iopub.status.idle":"2024-03-16T21:35:34.454475Z","shell.execute_reply.started":"2024-03-16T21:35:34.448680Z","shell.execute_reply":"2024-03-16T21:35:34.453646Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"filename = \"/kaggle/input/harmonic/sph_100_10_20.txt\"\nfull_dataset = CustomDataset(filename)\n\ntrain_size = int(0.8 * len(full_dataset))\nrest_size = len(full_dataset) - train_size\nval_size = rest_size // 2\ntest_size = rest_size // 2\ntrain_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(32))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:35:35.013409Z","iopub.execute_input":"2024-03-16T21:35:35.013708Z","iopub.status.idle":"2024-03-16T21:35:35.171588Z","shell.execute_reply.started":"2024-03-16T21:35:35.013685Z","shell.execute_reply":"2024-03-16T21:35:35.170866Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nBATCH_SIZE = 1024\ntrain_shuffle = True\nval_shuffle = False\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=train_shuffle)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=val_shuffle)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:35:35.774530Z","iopub.execute_input":"2024-03-16T21:35:35.774807Z","iopub.status.idle":"2024-03-16T21:35:35.779239Z","shell.execute_reply.started":"2024-03-16T21:35:35.774787Z","shell.execute_reply":"2024-03-16T21:35:35.778484Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for inputs, targets in train_dataloader:\n    assert inputs.shape[1] == 4 and targets.shape[1] == 2","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:35:36.727877Z","iopub.execute_input":"2024-03-16T21:35:36.728369Z","iopub.status.idle":"2024-03-16T21:35:36.914082Z","shell.execute_reply.started":"2024-03-16T21:35:36.728341Z","shell.execute_reply":"2024-03-16T21:35:36.913244Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.init as init\n\n# Define your autoencoder model\nclass Encoder(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(Encoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU()\n        )\n        self.bottleneck = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, input_size),\n        )\n        self.__init_weights()\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.bottleneck(x)\n        return x\n    \n    def __init_weights(self):\n        # Initialize linear layers using Kaiming (He) uniform initialization\n        for layer in [self.encoder, self.bottleneck]:\n            for m in layer.children():\n                if isinstance(m, nn.Linear):\n                    init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='tanh')\n                    if m.bias is not None:\n                        init.zeros_(m.bias)\n    \nclass Decoder(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(Decoder, self).__init__()\n        self.decoder = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, output_size)\n        )\n        self.__init_weights()\n\n    def forward(self, x):\n        x = self.decoder(x)\n        return x\n    \n    def __init_weights(self):\n        # Initialize linear layers using Kaiming (He) uniform initialization\n        for layer in [self.decoder]:\n            for m in layer.children():\n                if isinstance(m, nn.Linear):\n                    init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='tanh')\n                    if m.bias is not None:\n                        init.zeros_(m.bias)\n    \n    \nclass RegressionAutoencoder(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(RegressionAutoencoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T21:39:17.042084Z","iopub.execute_input":"2024-03-16T21:39:17.042427Z","iopub.status.idle":"2024-03-16T21:39:17.052927Z","shell.execute_reply.started":"2024-03-16T21:39:17.042402Z","shell.execute_reply":"2024-03-16T21:39:17.052313Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### Train encoder","metadata":{}},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\ndef encoder_train(model, dataloader, optimizer, loss_fn, epoch, writer, log_perc = 0.1):\n    model.train()\n    total_loss = 0\n    total_diff = 0\n    best_diff = 100\n\n    logs_steps = int(log_perc * len(dataloader))\n    start_step = epoch * len(dataloader)\n\n    before_lr = optimizer.param_groups[0][\"lr\"]\n    writer.add_scalar('Lr/Encoder Train', before_lr, epoch)\n    for idx, (inputs, _) in enumerate(dataloader):\n        inputs = inputs.to(device)\n        \n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n\n        loss = loss_fn(outputs, inputs)\n        diff = torch.abs(outputs - inputs).mean()\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        total_diff += diff.item()\n        \n        if idx % logs_steps == 0:\n            writer.add_scalar('Loss/Encoder Train', loss.item(), start_step + idx)\n            writer.add_scalar('Absolute Difference/Encoder Train', diff.item(), start_step + idx)\n            \n            if SHOULD_PRINT:\n                print(f\"Loss/Encoder Train: {loss.item()}\")\n                print(f\"Absolute Difference/Encoder Train: {diff.item()}\")\n\n    #scheduler.step()\n    after_lr = optimizer.param_groups[0][\"lr\"]\n    average_loss = total_loss / len(dataloader)\n    average_diff = total_diff / len(dataloader)\n    \n    writer.add_scalar('Avg Loss/Encoder Train', average_loss, epoch)\n    writer.add_scalar('Avg Absolute Difference/Encoder Train', average_diff, epoch)\n    writer.add_scalar('Lr/Encoder Train', after_lr, epoch)\n    \n    if SHOULD_PRINT:\n        print(f\"Avg Loss/Encoder Train: {average_loss}\")\n        print(f\"Absolute Difference/Encoder Train: {average_diff}\")\n        print(f\"Lr/Encoder Train: {after_lr}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:36:23.048074Z","iopub.execute_input":"2024-03-16T21:36:23.048856Z","iopub.status.idle":"2024-03-16T21:36:23.059174Z","shell.execute_reply.started":"2024-03-16T21:36:23.048832Z","shell.execute_reply":"2024-03-16T21:36:23.058390Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def encoder_validate(model, dataloader, loss_fn, epoch, writer):\n    model.eval()\n    total_loss = 0\n    total_diff = 0\n\n    with torch.no_grad():\n        for inputs, _ in dataloader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n\n            loss = loss_fn(outputs, inputs)\n            diff = torch.abs(outputs - inputs).mean()\n            \n            total_loss += loss.item()\n            total_diff += diff.item()\n\n    average_loss = total_loss / len(dataloader)\n    average_diff = total_diff / len(dataloader)\n\n    if writer is not None:\n        writer.add_scalar('Avg Loss/Encoder Val', average_loss, epoch)\n        writer.add_scalar('Avg Absolute Difference/Encoder Val', average_diff, epoch)\n    \n    if SHOULD_PRINT:\n        print(f\"Avg Loss/Encoder Val: {average_loss}\")\n        print(f\"Avg Absolute Difference/Encoder Val: {average_diff}\")\n\n    if epoch is not None:\n        print(f\"Epoch [{epoch+1}/{Encoder_NUM_EPOCHS}] Encoder Val Loss: {average_loss:.4f}, Val Diff: {average_diff:.15f}\")\n    else:\n        print(f\"Test Loss: {average_loss:.4f}, Encoder Test Diff: {average_diff:.15f}\")\n        \n    return average_diff","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:36:41.798427Z","iopub.execute_input":"2024-03-16T21:36:41.798764Z","iopub.status.idle":"2024-03-16T21:36:41.805745Z","shell.execute_reply.started":"2024-03-16T21:36:41.798736Z","shell.execute_reply":"2024-03-16T21:36:41.804927Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"device = \"cpu\"\nif torch.cuda.is_available():\n    device = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:36:42.008707Z","iopub.execute_input":"2024-03-16T21:36:42.009269Z","iopub.status.idle":"2024-03-16T21:36:42.013375Z","shell.execute_reply.started":"2024-03-16T21:36:42.009217Z","shell.execute_reply":"2024-03-16T21:36:42.012704Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"Encoder_LR = 5e-4 # too big\nEncoder_NUM_EPOCHS = 1000\nEncoder_MOMENTUM = 0.9\nEncoder_WEIGHT_DECAY = 0.99\nEncoder_MOMENTUM = 0.9\nEncoder_VALIDATION_STEPS = int(Encoder_NUM_EPOCHS * 0.1)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:36:42.203971Z","iopub.execute_input":"2024-03-16T21:36:42.204282Z","iopub.status.idle":"2024-03-16T21:36:42.209265Z","shell.execute_reply.started":"2024-03-16T21:36:42.204241Z","shell.execute_reply":"2024-03-16T21:36:42.207757Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"Encoder_VALIDATION_STEPS","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:36:42.438777Z","iopub.execute_input":"2024-03-16T21:36:42.439950Z","iopub.status.idle":"2024-03-16T21:36:42.445905Z","shell.execute_reply.started":"2024-03-16T21:36:42.439901Z","shell.execute_reply":"2024-03-16T21:36:42.445201Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}]},{"cell_type":"code","source":"encoder = Encoder(4, 256)\n\nencoder_loss_fn = nn.MSELoss()\nencoder_optimizer = optim.Adam(encoder.parameters(), lr=Encoder_LR)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:36:42.733579Z","iopub.execute_input":"2024-03-16T21:36:42.734091Z","iopub.status.idle":"2024-03-16T21:36:42.741044Z","shell.execute_reply.started":"2024-03-16T21:36:42.734060Z","shell.execute_reply":"2024-03-16T21:36:42.740199Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import datetime\n\nnow = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nwriter = SummaryWriter(f\"tb_logs/encoder/{now}\")\n\nencoder = encoder.to(device)\nbest_avg_diff = 1000\nfor idx, epoch in enumerate(tqdm(range(Encoder_NUM_EPOCHS))):\n    encoder_train(encoder, train_dataloader, encoder_optimizer, encoder_loss_fn, epoch, writer)\n\n    if idx % Encoder_VALIDATION_STEPS == 0:\n        average_diff = encoder_validate(encoder, val_dataloader, encoder_loss_fn, epoch, writer)\n        if average_diff < best_avg_diff:\n            best_avg_diff = average_diff\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': encoder.state_dict(),\n                'optimizer_state_dict': encoder_optimizer.state_dict(),\n                'loss': encoder_loss_fn,\n                }, f\"encoder_checkpoint-nosch-diff-{average_diff}.pth\")\n            \naverage_diff = encoder_validate(encoder, val_dataloader, encoder_loss_fn, epoch, writer)\nif average_diff < best_avg_diff:\n    best_avg_diff = average_diff\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': encoder.state_dict(),\n        'optimizer_state_dict': encoder_optimizer.state_dict(),\n        'loss': encoder_loss_fn,\n        }, f\"encoder_checkpoint-nosch-diff-{average_diff}.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:36:43.497807Z","iopub.execute_input":"2024-03-16T21:36:43.498169Z","iopub.status.idle":"2024-03-16T21:38:33.652442Z","shell.execute_reply.started":"2024-03-16T21:36:43.498143Z","shell.execute_reply":"2024-03-16T21:38:33.649365Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"  0%|          | 1/1000 [00:00<05:35,  2.98it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/1000] Encoder Val Loss: 6.5650, Val Diff: 1.961948633193970\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 101/1000 [00:33<05:24,  2.77it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [101/1000] Encoder Val Loss: 0.0004, Val Diff: 0.014144174133738\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 201/1000 [01:06<04:25,  3.01it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [201/1000] Encoder Val Loss: 0.0024, Val Diff: 0.043026874462763\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 301/1000 [01:40<03:42,  3.14it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [301/1000] Encoder Val Loss: 0.0004, Val Diff: 0.015002454010149\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 330/1000 [01:49<03:43,  3.00it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m best_avg_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(\u001b[38;5;28mrange\u001b[39m(Encoder_NUM_EPOCHS))):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mencoder_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m Encoder_VALIDATION_STEPS \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     12\u001b[0m         average_diff \u001b[38;5;241m=\u001b[39m encoder_validate(encoder, val_dataloader, encoder_loss_fn, epoch, writer)\n","Cell \u001b[0;32mIn[28], line 14\u001b[0m, in \u001b[0;36mencoder_train\u001b[0;34m(model, dataloader, optimizer, loss_fn, epoch, writer, log_perc)\u001b[0m\n\u001b[1;32m     12\u001b[0m before_lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLr/Encoder Train\u001b[39m\u001b[38;5;124m'\u001b[39m, before_lr, epoch)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (inputs, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     15\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","Cell \u001b[0;32mIn[16], line 16\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     15\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(targets)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### Train model","metadata":{}},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\n\ndef train(model, dataloader, optimizer, loss_fn, epoch, writer, log_perc = 0.1):\n    model.train()\n    total_loss = 0\n    total_diff = 0\n    best_diff = 100\n\n    logs_steps = int(log_perc * len(dataloader))\n    start_step = epoch * len(dataloader)\n\n    before_lr = optimizer.param_groups[0][\"lr\"]\n    writer.add_scalar('Lr/Train', before_lr, epoch)\n    for idx, (inputs, targets) in enumerate(dataloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n\n        loss = loss_fn(outputs, targets)\n        diff = torch.abs(outputs - targets).mean()\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        total_diff += diff.item()\n        \n        if idx % logs_steps == 0:\n            writer.add_scalar('Loss/Train', loss.item(), start_step + idx)\n            writer.add_scalar('Absolute Difference/Train', diff.item(), start_step + idx)\n            \n            if SHOULD_PRINT:\n                print(f\"Loss/Train: {loss.item()}\")\n                print(f\"Absolute Difference/Train: {diff.item()}\")\n\n    #scheduler.step()\n    after_lr = optimizer.param_groups[0][\"lr\"]\n    average_loss = total_loss / len(dataloader)\n    average_diff = total_diff / len(dataloader)\n    \n    writer.add_scalar('Avg Loss/Train', average_loss, epoch)\n    writer.add_scalar('Avg Absolute Difference/Train', average_diff, epoch)\n    writer.add_scalar('Lr/Train', after_lr, epoch)\n    \n    if SHOULD_PRINT:\n        print(f\"Avg Loss/Train: {average_loss}\")\n        print(f\"Absolute Difference/Train: {average_diff}\")\n        print(f\"Lr/Train: {after_lr}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:39:21.569933Z","iopub.execute_input":"2024-03-16T21:39:21.570671Z","iopub.status.idle":"2024-03-16T21:39:21.579039Z","shell.execute_reply.started":"2024-03-16T21:39:21.570648Z","shell.execute_reply":"2024-03-16T21:39:21.578147Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def validate(model, dataloader, loss_fn, epoch, writer):\n    model.eval()\n    total_loss = 0\n    total_diff = 0\n\n    with torch.no_grad():\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n\n            loss = loss_fn(outputs, targets)\n            diff = torch.abs(outputs - targets).mean()\n            \n            total_loss += loss.item()\n            total_diff += diff.item()\n\n    average_loss = total_loss / len(dataloader)\n    average_diff = total_diff / len(dataloader)\n\n    if writer is not None:\n        writer.add_scalar('Avg Loss/Val', average_loss, epoch)\n        writer.add_scalar('Avg Absolute Difference/Val', average_diff, epoch)\n    \n    if SHOULD_PRINT:\n        print(f\"Avg Loss/Val: {average_loss}\")\n        print(f\"Avg Absolute Difference/Val: {average_diff}\")\n\n    if epoch is not None:\n        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Val Loss: {average_loss:.4f}, Val Diff: {average_diff:.15f}\")\n    else:\n        print(f\"Test Loss: {average_loss:.4f}, Test Diff: {average_diff:.15f}\")\n        \n    return average_diff","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:39:22.078239Z","iopub.execute_input":"2024-03-16T21:39:22.078541Z","iopub.status.idle":"2024-03-16T21:39:22.085754Z","shell.execute_reply.started":"2024-03-16T21:39:22.078520Z","shell.execute_reply":"2024-03-16T21:39:22.084970Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"device = \"cpu\"\nif torch.cuda.is_available():\n    device = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:39:22.537489Z","iopub.execute_input":"2024-03-16T21:39:22.537789Z","iopub.status.idle":"2024-03-16T21:39:22.541609Z","shell.execute_reply.started":"2024-03-16T21:39:22.537758Z","shell.execute_reply":"2024-03-16T21:39:22.540745Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"LR = 5e-5\nNUM_EPOCHS = 1000\nMOMENTUM = 0.9\nWEIGHT_DECAY = 0.99\nMOMENTUM = 0.9\nVALIDATION_STEPS = int(NUM_EPOCHS * 0.1)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:39:38.712166Z","iopub.execute_input":"2024-03-16T21:39:38.712536Z","iopub.status.idle":"2024-03-16T21:39:38.717042Z","shell.execute_reply.started":"2024-03-16T21:39:38.712510Z","shell.execute_reply":"2024-03-16T21:39:38.716177Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"VALIDATION_STEPS","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:39:38.959329Z","iopub.execute_input":"2024-03-16T21:39:38.960175Z","iopub.status.idle":"2024-03-16T21:39:38.966451Z","shell.execute_reply.started":"2024-03-16T21:39:38.960142Z","shell.execute_reply":"2024-03-16T21:39:38.965678Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}]},{"cell_type":"code","source":"decoder = Decoder(4, 256, 2)\nmodel = RegressionAutoencoder(encoder, decoder)\n\nloss_fn = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:39:39.799902Z","iopub.execute_input":"2024-03-16T21:39:39.800210Z","iopub.status.idle":"2024-03-16T21:39:39.805677Z","shell.execute_reply.started":"2024-03-16T21:39:39.800188Z","shell.execute_reply":"2024-03-16T21:39:39.804788Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"import datetime\n\nnow = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nwriter = SummaryWriter(f\"tb_logs/model/{now}\")\n\nmodel = model.to(device)\nbest_avg_diff = 1000\nfor idx, epoch in enumerate(tqdm(range(NUM_EPOCHS))):\n    train(model, train_dataloader, optimizer, loss_fn, epoch, writer)\n\n    if idx % VALIDATION_STEPS == 0:\n        average_diff = validate(model, val_dataloader, loss_fn, epoch, writer)\n        if average_diff < best_avg_diff:\n            best_avg_diff = average_diff\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': loss_fn,\n                }, f\"checkpoint-nosch-diff-{average_diff}.pth\")\n            \naverage_diff = validate(model, val_dataloader, loss_fn, epoch, writer)\nif average_diff < best_avg_diff:\n    best_avg_diff = average_diff\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss_fn,\n        }, f\"checkpoint-nosch-diff-{average_diff}.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T21:39:40.267734Z","iopub.execute_input":"2024-03-16T21:39:40.268058Z","iopub.status.idle":"2024-03-16T21:45:42.175795Z","shell.execute_reply.started":"2024-03-16T21:39:40.268033Z","shell.execute_reply":"2024-03-16T21:45:42.174937Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"  0%|          | 1/1000 [00:00<06:09,  2.70it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/1000] Val Loss: 0.0998, Val Diff: 0.243626510103544\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 101/1000 [00:36<05:20,  2.81it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [101/1000] Val Loss: 0.0406, Val Diff: 0.132855425278346\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 201/1000 [01:12<04:41,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [201/1000] Val Loss: 0.0403, Val Diff: 0.130283370614052\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 301/1000 [01:48<04:07,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [301/1000] Val Loss: 0.0424, Val Diff: 0.142392655213674\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 401/1000 [02:25<04:11,  2.38it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [401/1000] Val Loss: 0.0399, Val Diff: 0.133532802263896\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 501/1000 [03:01<03:19,  2.50it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [501/1000] Val Loss: 0.0397, Val Diff: 0.128742218017578\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 601/1000 [03:37<02:25,  2.74it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [601/1000] Val Loss: 0.0445, Val Diff: 0.144551570216815\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 701/1000 [04:13<01:49,  2.74it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [701/1000] Val Loss: 0.0405, Val Diff: 0.131691560149193\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 801/1000 [04:49<01:11,  2.79it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [801/1000] Val Loss: 0.0395, Val Diff: 0.128067533175151\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 901/1000 [05:26<00:34,  2.86it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [901/1000] Val Loss: 0.0399, Val Diff: 0.130320549011230\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [06:01<00:00,  2.76it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1000/1000] Val Loss: 0.0392, Val Diff: 0.126322897771994\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}