{"cells":[{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:49.953568Z","iopub.status.busy":"2024-03-20T19:40:49.953109Z","iopub.status.idle":"2024-03-20T19:40:49.958969Z","shell.execute_reply":"2024-03-20T19:40:49.957744Z","shell.execute_reply.started":"2024-03-20T19:40:49.953531Z"},"trusted":true},"outputs":[],"source":["SHOULD_PRINT = False"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:49.961234Z","iopub.status.busy":"2024-03-20T19:40:49.960797Z","iopub.status.idle":"2024-03-20T19:40:49.971713Z","shell.execute_reply":"2024-03-20T19:40:49.970696Z","shell.execute_reply.started":"2024-03-20T19:40:49.961177Z"},"trusted":true},"outputs":[],"source":["import torch\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:49.974652Z","iopub.status.busy":"2024-03-20T19:40:49.974271Z","iopub.status.idle":"2024-03-20T19:40:49.985176Z","shell.execute_reply":"2024-03-20T19:40:49.984414Z","shell.execute_reply.started":"2024-03-20T19:40:49.974620Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","from typing import List\n","import random\n","\n","random.seed(42)\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, large_file_path, chunk_size, dataset_size=None):\n","        self.large_file_path = large_file_path\n","        self.line_offsets = self.get_line_offsets(\n","            large_file_path, chunk_size, dataset_size\n","        )\n","\n","    def get_line_offsets(\n","        self, path: str, chunk_size: int, dataset_size: int\n","    ) -> List[int]:\n","        offsets = [0]\n","        with open(path, \"rb\") as file:\n","            chunk = file.readlines(chunk_size)\n","            while chunk:\n","                for line in chunk:\n","                    offsets.append(offsets[-1] + len(line))\n","                chunk = file.readlines(chunk_size)\n","        offsets = offsets[:-1]\n","\n","        if dataset_size is not None:\n","            offsets = random.sample(offsets, dataset_size)\n","\n","        return offsets\n","\n","    def __len__(self):\n","        return len(self.line_offsets)\n","\n","    def __getitem__(self, line):\n","        offset = self.line_offsets[line]\n","        with open(self.large_file_path, \"r\", encoding=\"utf-8\") as f:\n","            f.seek(offset)\n","            line = f.readline()\n","            numbers = [float(num) for num in line.strip().split()]\n","            inputs, targets = numbers[:4], numbers[4:]\n","            return torch.tensor(inputs), torch.tensor(targets)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:49.986967Z","iopub.status.busy":"2024-03-20T19:40:49.986671Z","iopub.status.idle":"2024-03-20T19:40:50.395712Z","shell.execute_reply":"2024-03-20T19:40:50.394733Z","shell.execute_reply.started":"2024-03-20T19:40:49.986943Z"},"trusted":true},"outputs":[],"source":["filename = \"./data/full_dataset.txt\"\n","full_dataset = CustomDataset(filename, chunk_size=2**20, dataset_size=50000)\n","\n","train_size = int(0.8 * len(full_dataset))\n","rest_size = len(full_dataset) - train_size\n","val_size = rest_size // 2\n","test_size = rest_size // 2\n","train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n","    full_dataset,\n","    [train_size, val_size, test_size],\n","    generator=torch.Generator().manual_seed(32),\n",")"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:50.397833Z","iopub.status.busy":"2024-03-20T19:40:50.397454Z","iopub.status.idle":"2024-03-20T19:40:50.410448Z","shell.execute_reply":"2024-03-20T19:40:50.409141Z","shell.execute_reply.started":"2024-03-20T19:40:50.397804Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","BATCH_SIZE = 1024\n","train_shuffle = True\n","val_shuffle = False\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=train_shuffle)\n","val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=val_shuffle)\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:50.653427Z","iopub.status.busy":"2024-03-20T19:40:50.652941Z","iopub.status.idle":"2024-03-20T19:40:50.663146Z","shell.execute_reply":"2024-03-20T19:40:50.662188Z","shell.execute_reply.started":"2024-03-20T19:40:50.653393Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.init as init\n","\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(4, 128),\n","            nn.Tanh(),\n","            nn.Linear(128, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 128),\n","            nn.Tanh(),\n","            nn.Linear(128, 2)\n","        )\n","        self.__init_weights()\n","\n","    def __init_weights(self):\n","        # Initialize linear layers using Kaiming (He) uniform initialization\n","        for m in self.layers.children():\n","            if isinstance(m, nn.Linear):\n","                init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='tanh')\n","                if m.bias is not None:\n","                    init.zeros_(m.bias)\n","\n","    def forward(self, x):\n","        return self.layers(x)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:50.664838Z","iopub.status.busy":"2024-03-20T19:40:50.664219Z","iopub.status.idle":"2024-03-20T19:40:50.679723Z","shell.execute_reply":"2024-03-20T19:40:50.678290Z","shell.execute_reply.started":"2024-03-20T19:40:50.664797Z"},"trusted":true},"outputs":[],"source":["LR = 5e-4\n","NUM_EPOCHS = 1000\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 0.99\n","MOMENTUM = 0.9"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:50.683950Z","iopub.status.busy":"2024-03-20T19:40:50.683491Z","iopub.status.idle":"2024-03-20T19:40:50.692584Z","shell.execute_reply":"2024-03-20T19:40:50.691221Z","shell.execute_reply.started":"2024-03-20T19:40:50.683917Z"},"trusted":true},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:50.694479Z","iopub.status.busy":"2024-03-20T19:40:50.693893Z","iopub.status.idle":"2024-03-20T19:40:50.717065Z","shell.execute_reply":"2024-03-20T19:40:50.716034Z","shell.execute_reply.started":"2024-03-20T19:40:50.694417Z"},"trusted":true},"outputs":[],"source":["import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","\n","model = MLP()\n","\n","# checkpoint = torch.load(\"./checkpoints/checkpoint-0.0394-0.1206.pth\")\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","\n","loss_fn = nn.MSELoss()\n","optimizer = optim.SGD(\n","    model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM\n",")\n","# scheduler = lr_scheduler.LinearLR(\n","#     optimizer, start_factor=1.0, end_factor=0.3, total_iters=NUM_EPOCHS * 0.5\n","# )\n","scheduler = lr_scheduler.CyclicLR(\n","    optimizer, base_lr=5e-4, max_lr=5e-3, step_size_up=100\n",")"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:50.718581Z","iopub.status.busy":"2024-03-20T19:40:50.718085Z","iopub.status.idle":"2024-03-20T19:40:50.729613Z","shell.execute_reply":"2024-03-20T19:40:50.728565Z","shell.execute_reply.started":"2024-03-20T19:40:50.718550Z"},"trusted":true},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","\n","def train(model, dataloader, optimizer, scheduler, loss_fn, epoch, writer, log_perc = 0.1):\n","    model.train()\n","    total_loss = 0\n","    total_diff = 0\n","\n","    logs_steps = int(log_perc * len(dataloader))\n","    start_step = epoch * len(dataloader)\n","    \n","    before_lr = optimizer.param_groups[0][\"lr\"]\n","    writer.add_scalar('Lr/Train', before_lr, epoch)\n","    for idx, (inputs, targets) in enumerate(dataloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        \n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","\n","        loss = loss_fn(outputs, targets)\n","        diff = torch.abs(outputs - targets).mean()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        total_diff += diff.item()\n","        \n","        if idx % logs_steps == 0:\n","            writer.add_scalar('Loss/Train', loss.item(), start_step + idx)\n","            writer.add_scalar('Absolute Difference/Train', diff.item(), start_step + idx)\n","            \n","            if SHOULD_PRINT:\n","                print(f\"Loss/Train: {loss.item()}\")\n","                print(f\"Absolute Difference/Train: {diff.item()}\")\n","\n","    scheduler.step()\n","    after_lr = optimizer.param_groups[0][\"lr\"]\n","    average_loss = total_loss / len(dataloader)\n","    average_diff = total_diff / len(dataloader)\n","    \n","    writer.add_scalar('Avg Loss/Train', average_loss, epoch)\n","    writer.add_scalar('Avg Absolute Difference/Train', average_diff, epoch)\n","    writer.add_scalar('Lr/Train', after_lr, epoch)\n","    \n","    if SHOULD_PRINT:\n","        print(f\"Avg Loss/Train: {average_loss}\")\n","        print(f\"Absolute Difference/Train: {average_diff}\")\n","        print(f\"Lr/Train: {after_lr}\")\n","\n","    # print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Train Loss: {average_loss:.4f}, Train Diff: {average_diff:.15f}\")"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:50.732028Z","iopub.status.busy":"2024-03-20T19:40:50.730930Z","iopub.status.idle":"2024-03-20T19:40:50.746779Z","shell.execute_reply":"2024-03-20T19:40:50.745210Z","shell.execute_reply.started":"2024-03-20T19:40:50.731979Z"},"trusted":true},"outputs":[],"source":["def validate(model, dataloader, loss_fn, epoch, writer):\n","    model.eval()\n","    total_loss = 0\n","    total_diff = 0\n","\n","    with torch.no_grad():\n","        for inputs, targets in dataloader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","\n","            loss = loss_fn(outputs, targets)\n","            diff = torch.abs(outputs - targets).mean()\n","            \n","            total_loss += loss.item()\n","            total_diff += diff.item()\n","\n","    average_loss = total_loss / len(dataloader)\n","    average_diff = total_diff / len(dataloader)\n","\n","    if writer is not None:\n","        writer.add_scalar('Avg Loss/Val', average_loss, epoch)\n","        writer.add_scalar('Avg Absolute Difference/Val', average_diff, epoch)\n","    \n","    if SHOULD_PRINT:\n","        print(f\"Avg Loss/Val: {average_loss}\")\n","        print(f\"Avg Absolute Difference/Val: {average_diff}\")\n","\n","    if epoch is not None:\n","        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Val Loss: {average_loss:.4f}, Val Diff: {average_diff:.15f}\")\n","    else:\n","        print(f\"Test Loss: {average_loss:.4f}, Test Diff: {average_diff:.15f}\")\n","        \n","    return average_diff"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:40:50.771845Z","iopub.status.busy":"2024-03-20T19:40:50.771483Z","iopub.status.idle":"2024-03-20T19:49:07.780059Z","shell.execute_reply":"2024-03-20T19:49:07.778660Z","shell.execute_reply.started":"2024-03-20T19:40:50.771812Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/1000] Val Loss: 0.0498, Val Diff: 0.158337515592575\n","Epoch [2/1000] Val Loss: 0.0419, Val Diff: 0.137531974911690\n","Epoch [3/1000] Val Loss: 0.0393, Val Diff: 0.126101893186569\n","Epoch [4/1000] Val Loss: 0.0390, Val Diff: 0.123061005771160\n","Epoch [5/1000] Val Loss: 0.0390, Val Diff: 0.122508630156517\n","Epoch [6/1000] Val Loss: 0.0390, Val Diff: 0.122438395023346\n","Epoch [7/1000] Val Loss: 0.0390, Val Diff: 0.122440424561501\n","Epoch [8/1000] Val Loss: 0.0390, Val Diff: 0.122482036054134\n","Epoch [9/1000] Val Loss: 0.0390, Val Diff: 0.122459329664707\n","Epoch [10/1000] Val Loss: 0.0390, Val Diff: 0.122419911623001\n","Epoch [11/1000] Val Loss: 0.0390, Val Diff: 0.122426119446754\n","Epoch [12/1000] Val Loss: 0.0390, Val Diff: 0.122441469132900\n","Epoch [13/1000] Val Loss: 0.0390, Val Diff: 0.122413156926632\n","Epoch [14/1000] Val Loss: 0.0390, Val Diff: 0.122446504235268\n","Epoch [15/1000] Val Loss: 0.0390, Val Diff: 0.122495725750923\n","Epoch [16/1000] Val Loss: 0.0390, Val Diff: 0.122433744370937\n","Epoch [17/1000] Val Loss: 0.0390, Val Diff: 0.122484312951565\n","Epoch [18/1000] Val Loss: 0.0390, Val Diff: 0.122457130253315\n","Epoch [19/1000] Val Loss: 0.0390, Val Diff: 0.122429637610912\n","Epoch [20/1000] Val Loss: 0.0390, Val Diff: 0.122478757798672\n","Epoch [21/1000] Val Loss: 0.0390, Val Diff: 0.122401560842991\n","Epoch [22/1000] Val Loss: 0.0390, Val Diff: 0.122422796487808\n","Epoch [23/1000] Val Loss: 0.0390, Val Diff: 0.122399005293846\n","Epoch [24/1000] Val Loss: 0.0390, Val Diff: 0.122446134686470\n","Epoch [25/1000] Val Loss: 0.0390, Val Diff: 0.122412994503975\n","Epoch [26/1000] Val Loss: 0.0390, Val Diff: 0.122422288358212\n","Epoch [27/1000] Val Loss: 0.0390, Val Diff: 0.122434827685356\n","Epoch [28/1000] Val Loss: 0.0390, Val Diff: 0.122444115579128\n","Epoch [29/1000] Val Loss: 0.0390, Val Diff: 0.122439099848270\n","Epoch [30/1000] Val Loss: 0.0390, Val Diff: 0.122389131784439\n","Epoch [31/1000] Val Loss: 0.0390, Val Diff: 0.122478401660919\n","Epoch [32/1000] Val Loss: 0.0390, Val Diff: 0.122472119331360\n","Epoch [33/1000] Val Loss: 0.0390, Val Diff: 0.122505362331867\n","Epoch [34/1000] Val Loss: 0.0390, Val Diff: 0.122495019435883\n","Epoch [35/1000] Val Loss: 0.0390, Val Diff: 0.122460800409317\n","Epoch [36/1000] Val Loss: 0.0390, Val Diff: 0.122444188594818\n","Epoch [37/1000] Val Loss: 0.0390, Val Diff: 0.122439397871494\n","Epoch [38/1000] Val Loss: 0.0390, Val Diff: 0.122431467473507\n","Epoch [39/1000] Val Loss: 0.0390, Val Diff: 0.122484177350998\n","Epoch [40/1000] Val Loss: 0.0390, Val Diff: 0.122467599809170\n","Epoch [41/1000] Val Loss: 0.0390, Val Diff: 0.122401803731918\n","Epoch [42/1000] Val Loss: 0.0390, Val Diff: 0.122417822480202\n","Epoch [43/1000] Val Loss: 0.0390, Val Diff: 0.122447660565376\n","Epoch [44/1000] Val Loss: 0.0390, Val Diff: 0.122431840002537\n","Epoch [45/1000] Val Loss: 0.0390, Val Diff: 0.122530265152454\n","Epoch [46/1000] Val Loss: 0.0390, Val Diff: 0.122488203644753\n","Epoch [47/1000] Val Loss: 0.0390, Val Diff: 0.122473412752151\n","Epoch [48/1000] Val Loss: 0.0390, Val Diff: 0.122438278794289\n","Epoch [49/1000] Val Loss: 0.0390, Val Diff: 0.122420917451382\n","Epoch [50/1000] Val Loss: 0.0390, Val Diff: 0.122444786131382\n","Epoch [51/1000] Val Loss: 0.0390, Val Diff: 0.122469171881676\n","Epoch [52/1000] Val Loss: 0.0390, Val Diff: 0.122442017495632\n","Epoch [53/1000] Val Loss: 0.0390, Val Diff: 0.122397343814373\n","Epoch [54/1000] Val Loss: 0.0390, Val Diff: 0.122440920770168\n","Epoch [55/1000] Val Loss: 0.0390, Val Diff: 0.122430832684040\n","Epoch [56/1000] Val Loss: 0.0390, Val Diff: 0.122528564929962\n","Epoch [57/1000] Val Loss: 0.0390, Val Diff: 0.122414357960224\n","Epoch [58/1000] Val Loss: 0.0390, Val Diff: 0.122453621029854\n","Epoch [59/1000] Val Loss: 0.0390, Val Diff: 0.122486153244972\n","Epoch [60/1000] Val Loss: 0.0390, Val Diff: 0.122563436627388\n","Epoch [61/1000] Val Loss: 0.0390, Val Diff: 0.122416545450687\n","Epoch [62/1000] Val Loss: 0.0390, Val Diff: 0.122452178597450\n","Epoch [63/1000] Val Loss: 0.0390, Val Diff: 0.122457198798656\n","Epoch [64/1000] Val Loss: 0.0390, Val Diff: 0.122415016591549\n","Epoch [65/1000] Val Loss: 0.0390, Val Diff: 0.122406223416328\n","Epoch [66/1000] Val Loss: 0.0390, Val Diff: 0.122495613992214\n","Epoch [67/1000] Val Loss: 0.0390, Val Diff: 0.122483018040657\n","Epoch [68/1000] Val Loss: 0.0390, Val Diff: 0.122495977580547\n","Epoch [69/1000] Val Loss: 0.0390, Val Diff: 0.122475861012936\n","Epoch [70/1000] Val Loss: 0.0390, Val Diff: 0.122479030489922\n","Epoch [71/1000] Val Loss: 0.0390, Val Diff: 0.122475039958954\n","Epoch [72/1000] Val Loss: 0.0390, Val Diff: 0.122438514232635\n","Epoch [73/1000] Val Loss: 0.0390, Val Diff: 0.122460108995438\n","Epoch [74/1000] Val Loss: 0.0390, Val Diff: 0.122480483353138\n","Epoch [75/1000] Val Loss: 0.0390, Val Diff: 0.122404953837395\n","Epoch [76/1000] Val Loss: 0.0390, Val Diff: 0.122476929426193\n","Epoch [77/1000] Val Loss: 0.0390, Val Diff: 0.122558960318565\n","Epoch [78/1000] Val Loss: 0.0390, Val Diff: 0.122462804615498\n","Epoch [79/1000] Val Loss: 0.0390, Val Diff: 0.122465774416924\n","Epoch [80/1000] Val Loss: 0.0390, Val Diff: 0.122440506517887\n","Epoch [81/1000] Val Loss: 0.0390, Val Diff: 0.122536276280880\n","Epoch [82/1000] Val Loss: 0.0390, Val Diff: 0.122456480562687\n","Epoch [83/1000] Val Loss: 0.0390, Val Diff: 0.122470930218697\n","Epoch [84/1000] Val Loss: 0.0390, Val Diff: 0.122466853260994\n","Epoch [85/1000] Val Loss: 0.0390, Val Diff: 0.122512473165989\n","Epoch [86/1000] Val Loss: 0.0390, Val Diff: 0.122521635890007\n","Epoch [87/1000] Val Loss: 0.0390, Val Diff: 0.122469578683376\n","Epoch [88/1000] Val Loss: 0.0390, Val Diff: 0.122430947422981\n","Epoch [89/1000] Val Loss: 0.0390, Val Diff: 0.122455769777298\n","Epoch [90/1000] Val Loss: 0.0390, Val Diff: 0.122413824498653\n","Epoch [91/1000] Val Loss: 0.0390, Val Diff: 0.122438509762287\n","Epoch [92/1000] Val Loss: 0.0390, Val Diff: 0.122486919164658\n","Epoch [93/1000] Val Loss: 0.0390, Val Diff: 0.122453215718269\n","Epoch [94/1000] Val Loss: 0.0390, Val Diff: 0.122524276375771\n","Epoch [95/1000] Val Loss: 0.0390, Val Diff: 0.122445681691170\n","Epoch [96/1000] Val Loss: 0.0390, Val Diff: 0.122472600638866\n","Epoch [97/1000] Val Loss: 0.0390, Val Diff: 0.122501115500927\n","Epoch [98/1000] Val Loss: 0.0390, Val Diff: 0.122451131045818\n","Epoch [99/1000] Val Loss: 0.0390, Val Diff: 0.122473645210266\n","Epoch [100/1000] Val Loss: 0.0390, Val Diff: 0.122435566782951\n","Epoch [101/1000] Val Loss: 0.0390, Val Diff: 0.122458969056606\n","Epoch [102/1000] Val Loss: 0.0390, Val Diff: 0.122454330325127\n","Epoch [103/1000] Val Loss: 0.0390, Val Diff: 0.122498254477978\n","Epoch [104/1000] Val Loss: 0.0390, Val Diff: 0.122489570081234\n","Epoch [105/1000] Val Loss: 0.0390, Val Diff: 0.122477328777313\n","Epoch [106/1000] Val Loss: 0.0390, Val Diff: 0.122407592833042\n","Epoch [107/1000] Val Loss: 0.0390, Val Diff: 0.122436426579952\n","Epoch [108/1000] Val Loss: 0.0390, Val Diff: 0.122480636835098\n","Epoch [109/1000] Val Loss: 0.0390, Val Diff: 0.122405400872231\n","Epoch [110/1000] Val Loss: 0.0390, Val Diff: 0.122476804256439\n","Epoch [111/1000] Val Loss: 0.0390, Val Diff: 0.122467765212059\n","Epoch [112/1000] Val Loss: 0.0390, Val Diff: 0.122502690553665\n","Epoch [113/1000] Val Loss: 0.0390, Val Diff: 0.122484993934631\n","Epoch [114/1000] Val Loss: 0.0390, Val Diff: 0.122446206212044\n","Epoch [115/1000] Val Loss: 0.0390, Val Diff: 0.122465394437313\n","Epoch [116/1000] Val Loss: 0.0390, Val Diff: 0.122416730225086\n","Epoch [117/1000] Val Loss: 0.0390, Val Diff: 0.122473117709160\n","Epoch [118/1000] Val Loss: 0.0390, Val Diff: 0.122450780868530\n","Epoch [119/1000] Val Loss: 0.0390, Val Diff: 0.122438466548920\n","Epoch [120/1000] Val Loss: 0.0390, Val Diff: 0.122469392418861\n","Epoch [121/1000] Val Loss: 0.0390, Val Diff: 0.122472295165062\n","Epoch [122/1000] Val Loss: 0.0390, Val Diff: 0.122554036974907\n","Epoch [123/1000] Val Loss: 0.0390, Val Diff: 0.122459460794926\n","Epoch [124/1000] Val Loss: 0.0390, Val Diff: 0.122470112144947\n","Epoch [125/1000] Val Loss: 0.0390, Val Diff: 0.122479791939259\n","Epoch [126/1000] Val Loss: 0.0390, Val Diff: 0.122458393871784\n","Epoch [127/1000] Val Loss: 0.0390, Val Diff: 0.122497501969337\n","Epoch [128/1000] Val Loss: 0.0390, Val Diff: 0.122464740276337\n","Epoch [129/1000] Val Loss: 0.0390, Val Diff: 0.122517205774784\n","Epoch [130/1000] Val Loss: 0.0390, Val Diff: 0.122496607899666\n","Epoch [131/1000] Val Loss: 0.0390, Val Diff: 0.122392223775387\n","Epoch [132/1000] Val Loss: 0.0390, Val Diff: 0.122421413660049\n","Epoch [133/1000] Val Loss: 0.0390, Val Diff: 0.122451008856297\n","Epoch [134/1000] Val Loss: 0.0390, Val Diff: 0.122505578398705\n","Epoch [135/1000] Val Loss: 0.0390, Val Diff: 0.122447870671749\n","Epoch [136/1000] Val Loss: 0.0390, Val Diff: 0.122468842566013\n","Epoch [137/1000] Val Loss: 0.0390, Val Diff: 0.122433081269264\n","Epoch [138/1000] Val Loss: 0.0390, Val Diff: 0.122408857941628\n","Epoch [139/1000] Val Loss: 0.0390, Val Diff: 0.122462874650955\n","Epoch [140/1000] Val Loss: 0.0390, Val Diff: 0.122459828853607\n","Epoch [141/1000] Val Loss: 0.0390, Val Diff: 0.122509200870991\n","Epoch [142/1000] Val Loss: 0.0390, Val Diff: 0.122496585547924\n","Epoch [143/1000] Val Loss: 0.0390, Val Diff: 0.122441253066063\n","Epoch [144/1000] Val Loss: 0.0390, Val Diff: 0.122496637701988\n","Epoch [145/1000] Val Loss: 0.0390, Val Diff: 0.122443498671055\n","Epoch [146/1000] Val Loss: 0.0390, Val Diff: 0.122421748936176\n","Epoch [147/1000] Val Loss: 0.0390, Val Diff: 0.122378832101822\n","Epoch [148/1000] Val Loss: 0.0390, Val Diff: 0.122418330609798\n","Epoch [149/1000] Val Loss: 0.0390, Val Diff: 0.122464136779308\n","Epoch [150/1000] Val Loss: 0.0390, Val Diff: 0.122449599206448\n","Epoch [151/1000] Val Loss: 0.0390, Val Diff: 0.122464051842690\n","Epoch [152/1000] Val Loss: 0.0390, Val Diff: 0.122440272569656\n","Epoch [153/1000] Val Loss: 0.0390, Val Diff: 0.122431568801403\n","Epoch [154/1000] Val Loss: 0.0390, Val Diff: 0.122428575158119\n","Epoch [155/1000] Val Loss: 0.0390, Val Diff: 0.122448989748955\n","Epoch [156/1000] Val Loss: 0.0390, Val Diff: 0.122435456514359\n","Epoch [157/1000] Val Loss: 0.0390, Val Diff: 0.122438795864582\n","Epoch [158/1000] Val Loss: 0.0390, Val Diff: 0.122459842264652\n","Epoch [159/1000] Val Loss: 0.0390, Val Diff: 0.122424505650997\n","Epoch [160/1000] Val Loss: 0.0390, Val Diff: 0.122449000179768\n","Epoch [161/1000] Val Loss: 0.0390, Val Diff: 0.122426405549049\n","Epoch [162/1000] Val Loss: 0.0390, Val Diff: 0.122477130591869\n","Epoch [163/1000] Val Loss: 0.0390, Val Diff: 0.122440999746323\n","Epoch [164/1000] Val Loss: 0.0390, Val Diff: 0.122464014589787\n","Epoch [165/1000] Val Loss: 0.0390, Val Diff: 0.122448301315308\n","Epoch [166/1000] Val Loss: 0.0390, Val Diff: 0.122440662980080\n","Epoch [167/1000] Val Loss: 0.0390, Val Diff: 0.122478955984116\n","Epoch [168/1000] Val Loss: 0.0390, Val Diff: 0.122433850169182\n","Epoch [169/1000] Val Loss: 0.0390, Val Diff: 0.122420817613602\n","Epoch [170/1000] Val Loss: 0.0390, Val Diff: 0.122399237751961\n","Epoch [171/1000] Val Loss: 0.0390, Val Diff: 0.122456225752831\n","Epoch [172/1000] Val Loss: 0.0390, Val Diff: 0.122484274208546\n","Epoch [173/1000] Val Loss: 0.0390, Val Diff: 0.122443269193172\n","Epoch [174/1000] Val Loss: 0.0390, Val Diff: 0.122399246692657\n","Epoch [175/1000] Val Loss: 0.0390, Val Diff: 0.122431574761868\n","Epoch [176/1000] Val Loss: 0.0390, Val Diff: 0.122442510724068\n","Epoch [177/1000] Val Loss: 0.0390, Val Diff: 0.122430381178856\n","Epoch [178/1000] Val Loss: 0.0390, Val Diff: 0.122471784055233\n","Epoch [179/1000] Val Loss: 0.0390, Val Diff: 0.122505681216717\n","Epoch [180/1000] Val Loss: 0.0390, Val Diff: 0.122417254745960\n","Epoch [181/1000] Val Loss: 0.0390, Val Diff: 0.122510665655136\n","Epoch [182/1000] Val Loss: 0.0390, Val Diff: 0.122450198233128\n","Epoch [183/1000] Val Loss: 0.0390, Val Diff: 0.122501067817211\n","Epoch [184/1000] Val Loss: 0.0390, Val Diff: 0.122467996180058\n","Epoch [185/1000] Val Loss: 0.0390, Val Diff: 0.122441054880619\n","Epoch [186/1000] Val Loss: 0.0390, Val Diff: 0.122433844208717\n","Epoch [187/1000] Val Loss: 0.0390, Val Diff: 0.122428275644779\n","Epoch [188/1000] Val Loss: 0.0390, Val Diff: 0.122495742142200\n","Epoch [189/1000] Val Loss: 0.0390, Val Diff: 0.122448250651360\n","Epoch [190/1000] Val Loss: 0.0390, Val Diff: 0.122486802935600\n","Epoch [191/1000] Val Loss: 0.0390, Val Diff: 0.122478692233562\n","Epoch [192/1000] Val Loss: 0.0390, Val Diff: 0.122463928163052\n","Epoch [193/1000] Val Loss: 0.0390, Val Diff: 0.122457958757877\n","Epoch [194/1000] Val Loss: 0.0390, Val Diff: 0.122463633120060\n","Epoch [195/1000] Val Loss: 0.0390, Val Diff: 0.122455051541328\n","Epoch [196/1000] Val Loss: 0.0390, Val Diff: 0.122435693442821\n","Epoch [197/1000] Val Loss: 0.0390, Val Diff: 0.122452291846275\n","Epoch [198/1000] Val Loss: 0.0390, Val Diff: 0.122448605298996\n","Epoch [199/1000] Val Loss: 0.0390, Val Diff: 0.122429084777832\n","Epoch [200/1000] Val Loss: 0.0390, Val Diff: 0.122444720566273\n","Epoch [201/1000] Val Loss: 0.0390, Val Diff: 0.122445504367352\n","Epoch [202/1000] Val Loss: 0.0390, Val Diff: 0.122464780509472\n","Epoch [203/1000] Val Loss: 0.0390, Val Diff: 0.122483195364475\n","Epoch [204/1000] Val Loss: 0.0390, Val Diff: 0.122463308274746\n","Epoch [205/1000] Val Loss: 0.0390, Val Diff: 0.122458826005459\n","Epoch [206/1000] Val Loss: 0.0390, Val Diff: 0.122461681067944\n","Epoch [207/1000] Val Loss: 0.0390, Val Diff: 0.122437973320484\n","Epoch [208/1000] Val Loss: 0.0390, Val Diff: 0.122468732297421\n","Epoch [209/1000] Val Loss: 0.0390, Val Diff: 0.122446155548096\n","Epoch [210/1000] Val Loss: 0.0390, Val Diff: 0.122423680126667\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[45], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m best_avg_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m----> 9\u001b[0m     train(model, train_dataloader, optimizer, scheduler, loss_fn, epoch, writer)\n\u001b[0;32m     11\u001b[0m     average_diff \u001b[38;5;241m=\u001b[39m validate(model, val_dataloader, loss_fn, epoch, writer)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m average_diff \u001b[38;5;241m<\u001b[39m best_avg_diff:\n","Cell \u001b[1;32mIn[43], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, scheduler, loss_fn, epoch, writer, log_perc)\u001b[0m\n\u001b[0;32m     11\u001b[0m before_lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     12\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLr/Train\u001b[39m\u001b[38;5;124m'\u001b[39m, before_lr, epoch)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m     14\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[1;32mc:\\Users\\viori\\anaconda3\\envs\\ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\viori\\anaconda3\\envs\\ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32mc:\\Users\\viori\\anaconda3\\envs\\ai\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[1;32mc:\\Users\\viori\\anaconda3\\envs\\ai\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:361\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[1;32mc:\\Users\\viori\\anaconda3\\envs\\ai\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:361\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","Cell \u001b[1;32mIn[36], line 38\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     36\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_offsets[line]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlarge_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 38\u001b[0m     f\u001b[38;5;241m.\u001b[39mseek(offset)\n\u001b[0;32m     39\u001b[0m     line \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m     40\u001b[0m     numbers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(num) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit()]\n","File \u001b[1;32m<frozen codecs>:335\u001b[0m, in \u001b[0;36msetstate\u001b[1;34m(self, state)\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import datetime\n","\n","now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","writer = SummaryWriter(f\"tb_logs/{now}\")\n","\n","model = model.to(device)\n","best_avg_diff = 1000\n","for epoch in range(NUM_EPOCHS):\n","    train(model, train_dataloader, optimizer, scheduler, loss_fn, epoch, writer)\n","\n","    average_diff = validate(model, val_dataloader, loss_fn, epoch, writer)\n","    if average_diff < best_avg_diff:\n","        torch.save(\n","            {\n","                \"epoch\": epoch,\n","                \"model_state_dict\": model.state_dict(),\n","                \"optimizer_state_dict\": optimizer.state_dict(),\n","                \"scheduler_state_dict\": scheduler.state_dict(),\n","                \"loss\": loss_fn,\n","            },\n","            \"checkpoint.pth\",\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T19:49:13.766513Z","iopub.status.busy":"2024-03-20T19:49:13.766147Z","iopub.status.idle":"2024-03-20T19:49:13.835425Z","shell.execute_reply":"2024-03-20T19:49:13.834548Z","shell.execute_reply.started":"2024-03-20T19:49:13.766485Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [414/1000] Val Loss: 0.0376, Val Diff: 0.119426441689332\n"]},{"data":{"text/plain":["0.11942644168933232"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["validate(model, test_dataloader, loss_fn, epoch, None)"]},{"cell_type":"markdown","metadata":{},"source":["## Testing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.0376, Test Diff: 0.119426419337591\n"]},{"data":{"text/plain":["0.11942641933759053"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["checkpoint = torch.load(\"checkpoint.pth\")\n","model = MLP()\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model = model.to(device)\n","model.eval()\n","\n","validate(model, test_dataloader, loss_fn, None, None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4578667,"sourceId":7815780,"sourceType":"datasetVersion"},{"datasetId":4638556,"sourceId":7898704,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
