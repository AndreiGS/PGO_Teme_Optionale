{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch-summary in /usr/local/lib/python3.10/dist-packages (1.4.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.24.1)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.0.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.2-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.62.1 markdown-3.6 protobuf-5.26.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 werkzeug-3.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install torch-summary\n",
    "!pip install -U scikit-learn\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOULD_PRINT = True\n",
    "SEED = 32\n",
    "CONTINUE_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcde8134690>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, large_file_path, chunk_size, subset_size=50000):\n",
    "        self.large_file_path = large_file_path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.subset_size = subset_size\n",
    "        self.line_offsets = self.get_line_offsets(large_file_path, chunk_size)\n",
    "        self.scaler = StandardScaler()\n",
    "        print(\"Calculating mean and std...\")\n",
    "        self.mean, self.std = self.calculate_mean_std()\n",
    "        print(f\"Mean: {self.mean}, Std: {self.std}\")\n",
    "\n",
    "    def get_line_offsets(self, path: str, chunk_size: int) -> List[int]:\n",
    "        offsets = [0]\n",
    "        with open(path, \"rb\") as file:\n",
    "            chunk = file.readlines(chunk_size)\n",
    "            while chunk:\n",
    "                for line in chunk:\n",
    "                    offsets.append(offsets[-1] + len(line))\n",
    "                chunk = file.readlines(chunk_size)\n",
    "                print(f\"Lines found: {len(offsets)}\", end='\\r')\n",
    "        offsets = offsets[:-1]\n",
    "        print(f\"Lines found: {len(offsets)}\", end='\\n')\n",
    "        return offsets\n",
    "\n",
    "    def calculate_mean_std(self):\n",
    "        selected_offsets = random.sample(self.line_offsets, min(self.subset_size, len(self.line_offsets)))\n",
    "        features = []\n",
    "        for offset in selected_offsets:\n",
    "            with open(self.large_file_path, 'r', encoding='utf-8') as f:\n",
    "                f.seek(offset)\n",
    "                line = f.readline()\n",
    "                numbers = [float(num) for num in line.strip().split()]\n",
    "                features.append(numbers[:4])\n",
    "        features = np.array(features)\n",
    "        mean = np.mean(features, axis=0, dtype=np.float32)\n",
    "        std = np.std(features, axis=0, dtype=np.float32)\n",
    "        return mean, std\n",
    "\n",
    "    def standardize_features(self, features):\n",
    "        standardized_features = (features - self.mean) / self.std\n",
    "        return standardized_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offsets)\n",
    "\n",
    "    def __getitem__(self, line):\n",
    "        offset = self.line_offsets[line]\n",
    "        with open(self.large_file_path, 'r', encoding='utf-8') as f:\n",
    "            f.seek(offset)\n",
    "            line = f.readline()\n",
    "            numbers = [float(num) for num in line.strip().split()]\n",
    "            features, targets = numbers[:4], numbers[4:]\n",
    "            standardized_features = self.standardize_features(np.array(features))\n",
    "            return torch.tensor(standardized_features, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines found: 32902922\n",
      "Calculating mean and std...\n",
      "Mean: [52.98656    0.07032    1.5741991  3.115652 ], Std: [18.970188   32.557518    0.92616993  1.8189957 ]\n"
     ]
    }
   ],
   "source": [
    "filename = \"full_dataset_2.txt\"\n",
    "full_dataset = CustomDataset(filename, 2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.1 * len(full_dataset))\n",
    "rest_size = len(full_dataset) - train_size\n",
    "val_size = rest_size // 10\n",
    "test_size = rest_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290292"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 2 ** 20\n",
    "train_shuffle = True\n",
    "val_shuffle = False\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=train_shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=val_shuffle)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_layers, out_layers):\n",
    "        super(Block, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_layers, out_layers),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout1d(p=0.1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(4, 256),\n",
    "            Block(256, 256),\n",
    "            Block(256, 256),\n",
    "        ])\n",
    "        self.out = nn.Linear(256, 2)\n",
    "        \n",
    "        self.__init_weights()\n",
    "\n",
    "    def __init_weights(self):\n",
    "        layers = [self.blocks]\n",
    "        # Initialize linear layers using Kaiming (He) uniform initialization\n",
    "        for m in layers:\n",
    "            for layer in m:\n",
    "                self.__init_layer(layer)\n",
    "        self.__init_layer(self.out)\n",
    "                        \n",
    "    def __init_layer(self, layer):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            init.kaiming_uniform_(layer.weight, mode='fan_in', nonlinearity='tanh')\n",
    "            if layer.bias is not None:\n",
    "                init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks[0](x)\n",
    "        for block in self.blocks[1:]:\n",
    "            y = block(x)\n",
    "            x = x + y\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 5e-3\n",
    "NUM_EPOCHS = 50\n",
    "WEIGHT_DECAY = 0.99\n",
    "WEIGHT_DECAY_L1 = 1e-4\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "last_epoch = 0\n",
    "model = MLP()\n",
    "loss_mse = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY, nesterov=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=1.0,\n",
    "    end_factor=0.2,\n",
    "    total_iters=int(NUM_EPOCHS * 0.75))\n",
    "# scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, verbose=True) # set it to 10 next time because 1 epoch = 1 batch!\n",
    "if CONTINUE_MODEL:\n",
    "    checkpoint = torch.load(\"checkpoint.pth\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_mse = checkpoint['loss_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(model, (BATCH_SIZE, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train(model, dataloader, optimizer, scheduler, loss_fn, epoch, writer, log_perc = 0.1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_diff = 0\n",
    "\n",
    "    logs_steps = max(int(log_perc * len(dataloader)), 1)\n",
    "    start_step = epoch * len(dataloader)\n",
    "\n",
    "    before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    writer.add_scalar('Lr/Train', before_lr, epoch)\n",
    "    for idx, (inputs, targets) in enumerate(tqdm(dataloader)):\n",
    "        inputs, targets = inputs.to(device).to(torch.float32), targets.to(device).to(torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        diff = torch.abs(outputs - targets).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_diff += diff.item()\n",
    "        \n",
    "        if idx % logs_steps == 0:\n",
    "            writer.add_scalar('Loss/Train', loss.item(), start_step + idx)\n",
    "            writer.add_scalar('Absolute Difference/Train', diff.item(), start_step + idx)\n",
    "            \n",
    "            if SHOULD_PRINT:\n",
    "                print(f\"Loss/Train: {loss.item()}\")\n",
    "                print(f\"Absolute Difference/Train: {diff.item()}\")\n",
    "        \n",
    "    after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    average_diff = total_diff / len(dataloader)\n",
    "    \n",
    "    writer.add_scalar('Avg Loss/Train', average_loss, epoch)\n",
    "    writer.add_scalar('Avg Absolute Difference/Train', average_diff, epoch)\n",
    "    writer.add_scalar('Lr/Train', after_lr, epoch)\n",
    "    \n",
    "    if SHOULD_PRINT:\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Avg Loss/Train: {average_loss}\")\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Avg Absolute Difference/Train: {average_diff}\")\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Lr/Train: {after_lr}\")\n",
    "\n",
    "    # print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Train Loss: {average_loss:.4f}, Train Diff: {average_diff:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, loss_fn, epoch, writer):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_diff = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device).to(torch.float32), targets.to(device).to(torch.float32)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            diff = torch.abs(outputs - targets).mean()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_diff += diff.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    average_diff = total_diff / len(dataloader)\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('Avg Loss/Val', average_loss, epoch)\n",
    "        writer.add_scalar('Avg Absolute Difference/Val', average_diff, epoch)\n",
    "    \n",
    "    if SHOULD_PRINT:\n",
    "        print(f\"Avg Loss/Val: {average_loss}\")\n",
    "        print(f\"Avg Absolute Difference/Val: {average_diff}\")\n",
    "\n",
    "    if epoch is not None:\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Val Loss: {average_loss:.4f}, Val Diff: {average_diff:.15f}\")\n",
    "    else:\n",
    "        print(f\"Test Loss: {average_loss:.4f}, Test Diff: {average_diff:.15f}\")\n",
    "        \n",
    "    return average_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(outputs, targets):\n",
    "    loss = loss_mse(outputs, targets)\n",
    "#     loss_rmse = torch.sqrt(loss)\n",
    "#     l1_reg = torch.tensor(0., requires_grad=True)\n",
    "\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if 'weight' in name:\n",
    "#             l1_reg = l1_reg + torch.linalg.norm(param, 1)\n",
    "\n",
    "#     total_loss = (loss * 0.8 + loss_rmse * 0.2) + WEIGHT_DECAY_L1 * l1_reg\n",
    "#     total_loss = (loss * 0.8 + loss_rmse * 0.2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001: adjusting learning rate of group 0 to 9.9997e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:11<00:00, 191.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 2.010862350463867\n",
      "Absolute Difference/Train: 1.0789424180984497\n",
      "Avg Loss/Train: 2.010862350463867\n",
      "Avg Absolute Difference/Train: 1.0789424180984497\n",
      "Lr/Train: 0.000999972584682756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 1.0030797719955444\n",
      "Avg Absolute Difference/Val: 0.7709476351737976\n",
      "Epoch [1/48] Val Loss: 1.0031, Val Diff: 0.770947635173798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002: adjusting learning rate of group 0 to 9.9989e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:56<00:00, 176.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 1.1410406827926636\n",
      "Absolute Difference/Train: 0.7933563590049744\n",
      "Avg Loss/Train: 1.1410406827926636\n",
      "Avg Absolute Difference/Train: 0.7933563590049744\n",
      "Lr/Train: 0.0009998903417374227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003: adjusting learning rate of group 0 to 9.9975e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:53<00:00, 173.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.6173551678657532\n",
      "Absolute Difference/Train: 0.5897221565246582\n",
      "Avg Loss/Train: 0.6173551678657532\n",
      "Avg Absolute Difference/Train: 0.5897221565246582\n",
      "Lr/Train: 0.0009997532801828658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004: adjusting learning rate of group 0 to 9.9956e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.46004658937454224\n",
      "Absolute Difference/Train: 0.5257936716079712\n",
      "Avg Loss/Train: 0.46004658937454224\n",
      "Avg Absolute Difference/Train: 0.5257936716079712\n",
      "Lr/Train: 0.0009995614150494292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: adjusting learning rate of group 0 to 9.9931e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:06<00:00, 186.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.47990208864212036\n",
      "Absolute Difference/Train: 0.5443596243858337\n",
      "Avg Loss/Train: 0.47990208864212036\n",
      "Avg Absolute Difference/Train: 0.5443596243858337\n",
      "Lr/Train: 0.0009993147673772868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: adjusting learning rate of group 0 to 9.9901e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.49733343720436096\n",
      "Absolute Difference/Train: 0.5550215840339661\n",
      "Avg Loss/Train: 0.49733343720436096\n",
      "Avg Absolute Difference/Train: 0.5550215840339661\n",
      "Lr/Train: 0.0009990133642141358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: adjusting learning rate of group 0 to 9.9866e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.4409186840057373\n",
      "Absolute Difference/Train: 0.5239980220794678\n",
      "Avg Loss/Train: 0.4409186840057373\n",
      "Avg Absolute Difference/Train: 0.5239980220794678\n",
      "Lr/Train: 0.000998657238612229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.266435831785202\n",
      "Avg Absolute Difference/Val: 0.42115169763565063\n",
      "Epoch [7/48] Val Loss: 0.2664, Val Diff: 0.421151697635651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: adjusting learning rate of group 0 to 9.9825e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.33444470167160034\n",
      "Absolute Difference/Train: 0.45629027485847473\n",
      "Avg Loss/Train: 0.33444470167160034\n",
      "Avg Absolute Difference/Train: 0.45629027485847473\n",
      "Lr/Train: 0.0009982464296247522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: adjusting learning rate of group 0 to 9.9778e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.2289917916059494\n",
      "Absolute Difference/Train: 0.3751218318939209\n",
      "Avg Loss/Train: 0.2289917916059494\n",
      "Avg Absolute Difference/Train: 0.3751218318939209\n",
      "Lr/Train: 0.00099778098230154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010: adjusting learning rate of group 0 to 9.9726e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:53<00:00, 173.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.1591852903366089\n",
      "Absolute Difference/Train: 0.3089357018470764\n",
      "Avg Loss/Train: 0.1591852903366089\n",
      "Avg Absolute Difference/Train: 0.3089357018470764\n",
      "Lr/Train: 0.0009972609476841367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: adjusting learning rate of group 0 to 9.9669e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:53<00:00, 173.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.1300230473279953\n",
      "Absolute Difference/Train: 0.27560511231422424\n",
      "Avg Loss/Train: 0.1300230473279953\n",
      "Avg Absolute Difference/Train: 0.27560511231422424\n",
      "Lr/Train: 0.000996686382800198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: adjusting learning rate of group 0 to 9.9606e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.12831029295921326\n",
      "Absolute Difference/Train: 0.2722721993923187\n",
      "Avg Loss/Train: 0.12831029295921326\n",
      "Avg Absolute Difference/Train: 0.2722721993923187\n",
      "Lr/Train: 0.000996057350657239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: adjusting learning rate of group 0 to 9.9537e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:06<00:00, 186.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.13604657351970673\n",
      "Absolute Difference/Train: 0.2809402048587799\n",
      "Avg Loss/Train: 0.13604657351970673\n",
      "Avg Absolute Difference/Train: 0.2809402048587799\n",
      "Lr/Train: 0.0009953739202357217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.11268451809883118\n",
      "Avg Absolute Difference/Val: 0.2604462504386902\n",
      "Epoch [13/48] Val Loss: 0.1127, Val Diff: 0.260446250438690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: adjusting learning rate of group 0 to 9.9464e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:56<00:00, 176.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.14182943105697632\n",
      "Absolute Difference/Train: 0.28777003288269043\n",
      "Avg Loss/Train: 0.14182943105697632\n",
      "Avg Absolute Difference/Train: 0.28777003288269043\n",
      "Lr/Train: 0.0009946361664814943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: adjusting learning rate of group 0 to 9.9384e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.1409778594970703\n",
      "Absolute Difference/Train: 0.2874436676502228\n",
      "Avg Loss/Train: 0.1409778594970703\n",
      "Avg Absolute Difference/Train: 0.2874436676502228\n",
      "Lr/Train: 0.0009938441702975688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: adjusting learning rate of group 0 to 9.9300e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.13473807275295258\n",
      "Absolute Difference/Train: 0.2814745306968689\n",
      "Avg Loss/Train: 0.13473807275295258\n",
      "Avg Absolute Difference/Train: 0.2814745306968689\n",
      "Lr/Train: 0.0009929980185352525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: adjusting learning rate of group 0 to 9.9210e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.12613646686077118\n",
      "Absolute Difference/Train: 0.2729279100894928\n",
      "Avg Loss/Train: 0.12613646686077118\n",
      "Avg Absolute Difference/Train: 0.2729279100894928\n",
      "Lr/Train: 0.000992097803984621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00018: adjusting learning rate of group 0 to 9.9114e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.11771361529827118\n",
      "Absolute Difference/Train: 0.2641811966896057\n",
      "Avg Loss/Train: 0.11771361529827118\n",
      "Avg Absolute Difference/Train: 0.2641811966896057\n",
      "Lr/Train: 0.0009911436253643444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019: adjusting learning rate of group 0 to 9.9014e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.11072611808776855\n",
      "Absolute Difference/Train: 0.256664514541626\n",
      "Avg Loss/Train: 0.11072611808776855\n",
      "Avg Absolute Difference/Train: 0.256664514541626\n",
      "Lr/Train: 0.000990135587310861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.08300841599702835\n",
      "Avg Absolute Difference/Val: 0.22338245809078217\n",
      "Epoch [19/48] Val Loss: 0.0830, Val Diff: 0.223382458090782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020: adjusting learning rate of group 0 to 9.8907e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.10505234450101852\n",
      "Absolute Difference/Train: 0.25004857778549194\n",
      "Avg Loss/Train: 0.10505234450101852\n",
      "Avg Absolute Difference/Train: 0.25004857778549194\n",
      "Lr/Train: 0.0009890738003669028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021: adjusting learning rate of group 0 to 9.8796e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:13<00:00, 193.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.1001872718334198\n",
      "Absolute Difference/Train: 0.244081512093544\n",
      "Avg Loss/Train: 0.1001872718334198\n",
      "Avg Absolute Difference/Train: 0.244081512093544\n",
      "Lr/Train: 0.0009879583809693738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00022: adjusting learning rate of group 0 to 9.8679e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:10<00:00, 190.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.09541761130094528\n",
      "Absolute Difference/Train: 0.23796367645263672\n",
      "Avg Loss/Train: 0.09541761130094528\n",
      "Avg Absolute Difference/Train: 0.23796367645263672\n",
      "Lr/Train: 0.0009867894514365802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023: adjusting learning rate of group 0 to 9.8557e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.0904725193977356\n",
      "Absolute Difference/Train: 0.23135589063167572\n",
      "Avg Loss/Train: 0.0904725193977356\n",
      "Avg Absolute Difference/Train: 0.23135589063167572\n",
      "Lr/Train: 0.000985567139954818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00024: adjusting learning rate of group 0 to 9.8429e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:02<00:00, 182.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.08526286482810974\n",
      "Absolute Difference/Train: 0.22415700554847717\n",
      "Avg Loss/Train: 0.08526286482810974\n",
      "Avg Absolute Difference/Train: 0.22415700554847717\n",
      "Lr/Train: 0.0009842915805643156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: adjusting learning rate of group 0 to 9.8296e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.08015445619821548\n",
      "Absolute Difference/Train: 0.21669045090675354\n",
      "Avg Loss/Train: 0.08015445619821548\n",
      "Avg Absolute Difference/Train: 0.21669045090675354\n",
      "Lr/Train: 0.0009829629131445341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.06201629713177681\n",
      "Avg Absolute Difference/Val: 0.18978360295295715\n",
      "Epoch [25/48] Val Loss: 0.0620, Val Diff: 0.189783602952957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00026: adjusting learning rate of group 0 to 9.8158e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:56<00:00, 176.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.07521218061447144\n",
      "Absolute Difference/Train: 0.20906607806682587\n",
      "Avg Loss/Train: 0.07521218061447144\n",
      "Avg Absolute Difference/Train: 0.20906607806682587\n",
      "Lr/Train: 0.0009815812833988292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00027: adjusting learning rate of group 0 to 9.8015e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.07076855003833771\n",
      "Absolute Difference/Train: 0.20184017717838287\n",
      "Avg Loss/Train: 0.07076855003833771\n",
      "Avg Absolute Difference/Train: 0.20184017717838287\n",
      "Lr/Train: 0.0009801468428384716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00028: adjusting learning rate of group 0 to 9.7866e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.06699495017528534\n",
      "Absolute Difference/Train: 0.19531427323818207\n",
      "Avg Loss/Train: 0.06699495017528534\n",
      "Avg Absolute Difference/Train: 0.19531427323818207\n",
      "Lr/Train: 0.0009786597487660335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00029: adjusting learning rate of group 0 to 9.7712e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:56<00:00, 176.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.06388885527849197\n",
      "Absolute Difference/Train: 0.18963894248008728\n",
      "Avg Loss/Train: 0.06388885527849197\n",
      "Avg Absolute Difference/Train: 0.18963894248008728\n",
      "Lr/Train: 0.0009771201642581385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00030: adjusting learning rate of group 0 to 9.7553e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:53<00:00, 173.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.06131453439593315\n",
      "Absolute Difference/Train: 0.18467655777931213\n",
      "Avg Loss/Train: 0.06131453439593315\n",
      "Avg Absolute Difference/Train: 0.18467655777931213\n",
      "Lr/Train: 0.0009755282581475768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031: adjusting learning rate of group 0 to 9.7388e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:00<00:00, 180.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.05925538018345833\n",
      "Absolute Difference/Train: 0.1805427223443985\n",
      "Avg Loss/Train: 0.05925538018345833\n",
      "Avg Absolute Difference/Train: 0.1805427223443985\n",
      "Lr/Train: 0.0009738842050047929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.05040893703699112\n",
      "Avg Absolute Difference/Val: 0.16479803621768951\n",
      "Epoch [31/48] Val Loss: 0.0504, Val Diff: 0.164798036217690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00032: adjusting learning rate of group 0 to 9.7219e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:56<00:00, 176.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.05761255323886871\n",
      "Absolute Difference/Train: 0.17712785303592682\n",
      "Avg Loss/Train: 0.05761255323886871\n",
      "Avg Absolute Difference/Train: 0.17712785303592682\n",
      "Lr/Train: 0.0009721881851187407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00033: adjusting learning rate of group 0 to 9.7044e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.05623026192188263\n",
      "Absolute Difference/Train: 0.17425915598869324\n",
      "Avg Loss/Train: 0.05623026192188263\n",
      "Avg Absolute Difference/Train: 0.17425915598869324\n",
      "Lr/Train: 0.0009704403844771128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00034: adjusting learning rate of group 0 to 9.6864e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:53<00:00, 173.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.05510653555393219\n",
      "Absolute Difference/Train: 0.17185010015964508\n",
      "Avg Loss/Train: 0.05510653555393219\n",
      "Avg Absolute Difference/Train: 0.17185010015964508\n",
      "Lr/Train: 0.0009686409947459458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00035: adjusting learning rate of group 0 to 9.6679e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.05409380421042442\n",
      "Absolute Difference/Train: 0.16974353790283203\n",
      "Avg Loss/Train: 0.05409380421042442\n",
      "Avg Absolute Difference/Train: 0.16974353790283203\n",
      "Lr/Train: 0.0009667902132486009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00036: adjusting learning rate of group 0 to 9.6489e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:56<00:00, 176.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.05324969068169594\n",
      "Absolute Difference/Train: 0.16789691150188446\n",
      "Avg Loss/Train: 0.05324969068169594\n",
      "Avg Absolute Difference/Train: 0.16789691150188446\n",
      "Lr/Train: 0.0009648882429441257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00037: adjusting learning rate of group 0 to 9.6294e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.052528802305459976\n",
      "Absolute Difference/Train: 0.1663287729024887\n",
      "Avg Loss/Train: 0.052528802305459976\n",
      "Avg Absolute Difference/Train: 0.1663287729024887\n",
      "Lr/Train: 0.0009629352924049974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.04733678326010704\n",
      "Avg Absolute Difference/Val: 0.15687890350818634\n",
      "Epoch [37/48] Val Loss: 0.0473, Val Diff: 0.156878903508186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00038: adjusting learning rate of group 0 to 9.6093e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:56<00:00, 176.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.05181466415524483\n",
      "Absolute Difference/Train: 0.16481851041316986\n",
      "Avg Loss/Train: 0.05181466415524483\n",
      "Avg Absolute Difference/Train: 0.16481851041316986\n",
      "Lr/Train: 0.0009609315757942503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00039: adjusting learning rate of group 0 to 9.5888e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.051219791173934937\n",
      "Absolute Difference/Train: 0.16354601085186005\n",
      "Avg Loss/Train: 0.051219791173934937\n",
      "Avg Absolute Difference/Train: 0.16354601085186005\n",
      "Lr/Train: 0.0009588773128419905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00040: adjusting learning rate of group 0 to 9.5677e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.05068863555788994\n",
      "Absolute Difference/Train: 0.16237367689609528\n",
      "Avg Loss/Train: 0.05068863555788994\n",
      "Avg Absolute Difference/Train: 0.16237367689609528\n",
      "Lr/Train: 0.0009567727288213005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00041: adjusting learning rate of group 0 to 9.5462e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:57<00:00, 177.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.050143033266067505\n",
      "Absolute Difference/Train: 0.16123194992542267\n",
      "Avg Loss/Train: 0.050143033266067505\n",
      "Avg Absolute Difference/Train: 0.16123194992542267\n",
      "Lr/Train: 0.0009546180545235343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00042: adjusting learning rate of group 0 to 9.5241e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:00<00:00, 180.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.04969315975904465\n",
      "Absolute Difference/Train: 0.16025269031524658\n",
      "Avg Loss/Train: 0.04969315975904465\n",
      "Avg Absolute Difference/Train: 0.16025269031524658\n",
      "Lr/Train: 0.0009524135262330098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00043: adjusting learning rate of group 0 to 9.5016e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.04925259202718735\n",
      "Absolute Difference/Train: 0.15926162898540497\n",
      "Avg Loss/Train: 0.04925259202718735\n",
      "Avg Absolute Difference/Train: 0.15926162898540497\n",
      "Lr/Train: 0.0009501593857010968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.04581853002309799\n",
      "Avg Absolute Difference/Val: 0.15246345102787018\n",
      "Epoch [43/48] Val Loss: 0.0458, Val Diff: 0.152463451027870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00044: adjusting learning rate of group 0 to 9.4786e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.048828739672899246\n",
      "Absolute Difference/Train: 0.15832269191741943\n",
      "Avg Loss/Train: 0.048828739672899246\n",
      "Avg Absolute Difference/Train: 0.15832269191741943\n",
      "Lr/Train: 0.0009478558801197064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00045: adjusting learning rate of group 0 to 9.4550e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:17<00:00, 197.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.04844822734594345\n",
      "Absolute Difference/Train: 0.1574753224849701\n",
      "Avg Loss/Train: 0.04844822734594345\n",
      "Avg Absolute Difference/Train: 0.1574753224849701\n",
      "Lr/Train: 0.0009455032620941839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00046: adjusting learning rate of group 0 to 9.4310e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:03<00:00, 183.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.04806199669837952\n",
      "Absolute Difference/Train: 0.15657076239585876\n",
      "Avg Loss/Train: 0.04806199669837952\n",
      "Avg Absolute Difference/Train: 0.15657076239585876\n",
      "Lr/Train: 0.0009431017896156073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00047: adjusting learning rate of group 0 to 9.4065e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:55<00:00, 175.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.04770892113447189\n",
      "Absolute Difference/Train: 0.1557026207447052\n",
      "Avg Loss/Train: 0.04770892113447189\n",
      "Avg Absolute Difference/Train: 0.1557026207447052\n",
      "Lr/Train: 0.0009406517260324961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00048: adjusting learning rate of group 0 to 9.3815e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:58<00:00, 178.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/Train: 0.04734838753938675\n",
      "Absolute Difference/Train: 0.15482866764068604\n",
      "Avg Loss/Train: 0.04734838753938675\n",
      "Avg Absolute Difference/Train: 0.15482866764068604\n",
      "Lr/Train: 0.0009381533400219318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(f\"tb_logs/{now}\")\n",
    "\n",
    "VALIDATION_STEPS = 6\n",
    "\n",
    "model = model.to(device)\n",
    "best_avg_diff = 1000\n",
    "\n",
    "for idx, epoch in enumerate(range(last_epoch, NUM_EPOCHS)):\n",
    "    train(model, train_dataloader, optimizer, scheduler, total_loss, epoch, writer, log_perc=0.2)\n",
    "\n",
    "    if idx % VALIDATION_STEPS == 0:\n",
    "        average_diff = validate(model, val_dataloader, total_loss, epoch, writer)\n",
    "        if average_diff < best_avg_diff:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss_mse': loss_mse,\n",
    "                }, \"checkpoint.pth\")\n",
    "\n",
    "# Launch TensorBoard: `tensorboard --logdir=tb_logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss/Val: 0.044784296836171834\n",
      "Avg Absolute Difference/Val: 0.14934985978262766\n",
      "Epoch [48/48] Val Loss: 0.0448, Val Diff: 0.149349859782628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14934985978262766"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, test_dataloader, total_loss, epoch, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4578667,
     "sourceId": 7960124,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 18456,
     "sourceId": 22283,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
